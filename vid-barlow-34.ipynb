{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import lightly\n",
    "import lightly.models as models\n",
    "import lightly.loss as loss\n",
    "import lightly.data as data\n",
    "from lightly.models.barlowtwins import BarlowTwins\n",
    "from lightly.models.simclr import SimCLR\n",
    "\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe72407",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointDir = 'barlow-custom34-1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01bd865",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, limit=0):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "\n",
    "        if limit == 0:\n",
    "            self.num_images = len(os.listdir(self.image_dir))\n",
    "        else:\n",
    "            self.num_images = limit\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "            \n",
    "        if self.transform == None:\n",
    "            return img, self.labels[idx]            \n",
    "\n",
    "        return self.transform(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9201096b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            sigma = random.random() * 1.9 + 0.1\n",
    "            return img.filter(ImageFilter.GaussianBlur(sigma))\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "\n",
    "class Solarization(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            return ImageOps.solarize(img)\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19a2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transform:\n",
    "    def __init__(self):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(96, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            GaussianBlur(p=1.0),\n",
    "            Solarization(p=0.0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_prime = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(96, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            GaussianBlur(p=0.1),\n",
    "            Solarization(p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, x):\n",
    "        y1 = self.transform(x)\n",
    "        y2 = self.transform_prime(x)\n",
    "        return y1, y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3332166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LARS(optim.Optimizer):\n",
    "    def __init__(self, params, lr, weight_decay=0, momentum=0.9, eta=0.001,\n",
    "                 weight_decay_filter=None, lars_adaptation_filter=None):\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay, momentum=momentum,\n",
    "                        eta=eta, weight_decay_filter=weight_decay_filter,\n",
    "                        lars_adaptation_filter=lars_adaptation_filter)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def step(self):\n",
    "        for g in self.param_groups:\n",
    "            for p in g['params']:\n",
    "                dp = p.grad\n",
    "\n",
    "                if dp is None:\n",
    "                    continue\n",
    "\n",
    "                if g['weight_decay_filter'] is None or not g['weight_decay_filter'](p):\n",
    "                    dp = dp.add(p, alpha=g['weight_decay'])\n",
    "\n",
    "                if g['lars_adaptation_filter'] is None or not g['lars_adaptation_filter'](p):\n",
    "                    param_norm = torch.norm(p)\n",
    "                    update_norm = torch.norm(dp)\n",
    "                    one = torch.ones_like(param_norm)\n",
    "                    q = torch.where(param_norm > 0.,\n",
    "                                    torch.where(update_norm > 0,\n",
    "                                                (g['eta'] * param_norm / update_norm), one), one)\n",
    "                    dp = dp.mul(q)\n",
    "\n",
    "                param_state = self.state[p]\n",
    "                if 'mu' not in param_state:\n",
    "                    param_state['mu'] = torch.zeros_like(p)\n",
    "                mu = param_state['mu']\n",
    "                mu.mul_(g['momentum']).add_(dp)\n",
    "\n",
    "                p.add_(mu, alpha=-g['lr'])\n",
    "\n",
    "\n",
    "def exclude_bias_and_norm(p):\n",
    "    return p.ndim == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921dd4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset from your image folder\n",
    "dataset = CustomDataset(root='/dataset', split='unlabeled', transform=Transform())\n",
    "\n",
    "# build a PyTorch dataloader\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=1024, shuffle=True, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970de8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwins(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.backbone = torchvision.models.resnet34(zero_init_residual=True)\n",
    "        self.backbone = resnet.get_custom_resnet34()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # projector\n",
    "        sizes = [512] + list(map(int, '1024-1024-1024'.split('-')))\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=False))\n",
    "            layers.append(nn.BatchNorm1d(sizes[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1], bias=False))\n",
    "        self.projector = nn.Sequential(*layers)\n",
    "\n",
    "        # normalization layer for the representations z1 and z2\n",
    "        self.bn = nn.BatchNorm1d(sizes[-1], affine=False)\n",
    "\n",
    "    def forward(self, y1, y2):\n",
    "        z1 = self.projector(self.backbone(y1))\n",
    "        z2 = self.projector(self.backbone(y2))\n",
    "\n",
    "        # empirical cross-correlation matrix\n",
    "        c = self.bn(z1).T @ self.bn(z2)\n",
    "\n",
    "        # sum the cross-correlation matrix between all gpus\n",
    "        c.div_(1024)\n",
    "#         torch.distributed.all_reduce(c)\n",
    "\n",
    "        # use --scale-loss to multiply the loss by a constant factor\n",
    "        # see the Issues section of the readme\n",
    "        on_diag = torch.diagonal(c).add_(-1).pow_(2).sum().mul(1/32)\n",
    "        off_diag = off_diagonal(c).pow_(2).sum().mul(1/32)\n",
    "        loss = on_diag + 3.9e-3 * off_diag\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9506a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def off_diagonal(x):\n",
    "    # return a flattened view of the off-diagonal elements of a square matrix\n",
    "    n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd89b081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_learning_rate(optimizer, loader, step):\n",
    "    max_steps = 300 * len(loader)\n",
    "    warmup_steps = 10 * len(loader)\n",
    "    base_lr = 0.2 * 1024 / 256\n",
    "    if step < warmup_steps:\n",
    "        lr = base_lr * step / warmup_steps\n",
    "    else:\n",
    "        step -= warmup_steps\n",
    "        max_steps -= warmup_steps\n",
    "        q = 0.5 * (1 + math.cos(math.pi * step / max_steps))\n",
    "        end_lr = base_lr * 0.001\n",
    "        lr = base_lr * q + end_lr * (1 - q)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8927b210",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model = BarlowTwins().cuda()\n",
    "# model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "optimizer = LARS(model.parameters(), lr=0, weight_decay=1e-6,\n",
    "                 weight_decay_filter=exclude_bias_and_norm,\n",
    "                 lars_adaptation_filter=exclude_bias_and_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1459e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# automatically resume from checkpoint if it exists\n",
    "if os.path.isfile('/scratch/vvb238/' + checkpointDir + '/checkpoint.pth'):\n",
    "    ckpt = torch.load('/scratch/vvb238/' + checkpointDir + '/checkpoint.pth',\n",
    "                      map_location='cpu')\n",
    "    start_epoch = ckpt['epoch']\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "    optimizer.load_state_dict(ckpt['optimizer'])\n",
    "else:\n",
    "    start_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e904a0f3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "for epoch in range(start_epoch, 300):\n",
    "#     sampler.set_epoch(epoch)\n",
    "    for step, ((y1, y2), _) in enumerate(loader, start=epoch * len(loader)):\n",
    "        y1 = y1.cuda()\n",
    "        y2 = y2.cuda()\n",
    "        lr = adjust_learning_rate(optimizer, loader, step)\n",
    "        optimizer.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            loss = model.forward(y1, y2)\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        if step % 10 == 0:\n",
    "#             torch.distributed.reduce(loss.div_(args.world_size), 0)\n",
    "#             if args.rank == 0:\n",
    "            stats = dict(epoch=epoch, step=step, learning_rate=lr,\n",
    "                         loss=loss.item(),\n",
    "                         time=int(time.time() - start_time))\n",
    "            print(json.dumps(stats))\n",
    "#                 print(json.dumps(stats), file=stats_file)\n",
    "        # save checkpoint\n",
    "    state = dict(epoch=epoch + 1, model=model.state_dict(),\n",
    "                 optimizer=optimizer.state_dict())\n",
    "    torch.save(state, '/scratch/vvb238/' + checkpointDir + '/checkpoint.pth')\n",
    "    \n",
    "torch.save(model.backbone.state_dict(),\n",
    "           '/scratch/vvb238/' + checkpointDir + '/resnet50.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fae8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1a465c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS PART TAKES THE MODEL IN THE MIDDLE AND USES IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa4d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            sigma = random.random() * 1.9 + 0.1\n",
    "            return img.filter(ImageFilter.GaussianBlur(sigma))\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "\n",
    "class Solarization(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            return ImageOps.solarize(img)\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUImageNetDataModule(pl.LightningDataModule):\n",
    "  \n",
    "    def train_dataloader(self):\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(96, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "#             transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.1\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.1),\n",
    "            GaussianBlur(p=0.2),\n",
    "            Solarization(p=0.0),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        trainset = CustomDataset(root='/dataset', split=\"train\", transform=train_transform)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        eval_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        evalset = CustomDataset(root='/dataset', split=\"val\", transform=eval_transform)\n",
    "        eval_loader = torch.utils.data.DataLoader(evalset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return eval_loader\n",
    "    \n",
    "nyudata = NYUImageNetDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0318a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isfile('/scratch/vvb238/' + checkpointDir + '/best-checkpoint.pth'):\n",
    "    ckpt = torch.load('/scratch/vvb238/' + checkpointDir + '/best-checkpoint.pth',\n",
    "                      map_location='cpu')\n",
    "    model.load_state_dict(ckpt['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf938ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclr.modules.identity import Identity\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class ResNetClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.backbone = torchvision.models.resnet34(zero_init_residual=True)\n",
    "        self.backbone = resnet.get_custom_resnet34()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.load_state_dict(model.backbone.state_dict())\n",
    "        \n",
    "        self.lastLayer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(1024, 800),\n",
    "        )\n",
    "#         self.lastLayer = torch.nn.Linear(512, 800)\n",
    "        for layer in self.lastLayer.modules():\n",
    "           if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.01)\n",
    "                layer.bias.data.zero_()\n",
    "        \n",
    "        self.param_groups = [dict(params=self.lastLayer.parameters(), lr=0.01)]\n",
    "        self.param_groups.append(dict(params=model.parameters(), lr=0.0005))\n",
    "        \n",
    "        self.criterion=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "#         x = self.relu(self.projector(x))\n",
    "        x = self.lastLayer(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        classProbs = self.forward(data)\n",
    "        loss = self.criterion(classProbs, label)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        logits = F.log_softmax(out, dim=-1)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.param_groups, 0, momentum=0.9, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS, verbose=True)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbee3f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "classifier = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834b616",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_last=True)\n",
    "classifier_trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/vvb238/classifier-' + checkpointDir, profiler=\"simple\",\n",
    "                     limit_val_batches= 0.3, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a45e100",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_trainer.fit(classifier, train_dataloader=nyudata.train_dataloader(), val_dataloaders=nyudata.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b5bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = classifier.cuda()\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in nyudata.val_dataloader():\n",
    "        images, labels = batch\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ab1fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (100 * correct / total)\n",
    "print('/scratch/vvb238/' + checkpointDir + '/' + str(accuracy).replace('.', '') + '-classifier.pth')\n",
    "torch.save(classifier.state_dict(),\n",
    "           '/scratch/vvb238/' + checkpointDir + '/' + str(accuracy).replace('.', '') + '-classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772556df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6582c768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
