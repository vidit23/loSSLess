{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce5717f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nr2229/.local/lib/python3.8/site-packages/lightly/api/version_checking.py:54: Warning: There is a newer version of the package available. For compatability reasons, please upgrade your current version:pip install lightly==1.1.7\n",
      "  warnings.warn(Warning(warning))\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "# from utils import BenchmarkModule\n",
    "import lightly\n",
    "import lightly.models as models\n",
    "import lightly.loss as loss\n",
    "# import lightly.data as data\n",
    "from lightly.models.barlowtwins import BarlowTwins\n",
    "from lightly.models.simclr import SimCLR\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from byol_pytorch import BYOL\n",
    "import lightly\n",
    "from lightly.models._momentum import _MomentumEncoderMixin\n",
    "from lightly.models.batchnorm import get_norm_layer\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, limit=0):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "\n",
    "        if limit == 0:\n",
    "            self.num_images = len(os.listdir(self.image_dir))\n",
    "        else:\n",
    "            self.num_images = limit\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "            \n",
    "        if self.transform == None:\n",
    "            return img, self.labels[idx]            \n",
    "\n",
    "        return self.transform(img), self.labels[idx], 2\n",
    "    \n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(p=0.5),transforms.RandomVerticalFlip(p=0.5)])   \n",
    "# the collate function applies random transforms to the input images\n",
    "collate_fn = lightly.data.SimCLRCollateFunction(\n",
    "    input_size=32,\n",
    "    gaussian_blur=0.,\n",
    ")\n",
    "\n",
    "# create a dataset from your image folder\n",
    "dataset = CustomDataset(root='/dataset', split='unlabeled', transform=train_transform)\n",
    "\n",
    "# build a PyTorch dataloader\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=512, shuffle=True, collate_fn=collate_fn, pin_memory=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26cf242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_predict(feature, feature_bank, feature_labels, classes: int, knn_k: int, knn_t: float):\n",
    "    \"\"\"Helper method to run kNN predictions on features based on a feature bank\n",
    "    Args:\n",
    "        feature: Tensor of shape [N, D] consisting of N D-dimensional features\n",
    "        feature_bank: Tensor of a database of features used for kNN\n",
    "        feature_labels: Labels for the features in our feature_bank\n",
    "        classes: Number of classes (e.g. 10 for CIFAR-10)\n",
    "        knn_k: Number of k neighbors used for kNN\n",
    "        knn_t: \n",
    "    \"\"\"\n",
    "    # compute cos similarity between each feature vector and feature bank ---> [B, N]\n",
    "    sim_matrix = torch.mm(feature, feature_bank)\n",
    "    # [B, K]\n",
    "    sim_weight, sim_indices = sim_matrix.topk(k=knn_k, dim=-1)\n",
    "    # [B, K]\n",
    "    sim_labels = torch.gather(feature_labels.expand(feature.size(0), -1), dim=-1, index=sim_indices)\n",
    "    # we do a reweighting of the similarities \n",
    "    sim_weight = (sim_weight / knn_t).exp()\n",
    "    # counts for each class\n",
    "    one_hot_label = torch.zeros(feature.size(0) * knn_k, classes, device=sim_labels.device)\n",
    "    # [B*K, C]\n",
    "    one_hot_label = one_hot_label.scatter(dim=-1, index=sim_labels.view(-1, 1), value=1.0)\n",
    "    # weighted score ---> [B, C]\n",
    "    pred_scores = torch.sum(one_hot_label.view(feature.size(0), -1, classes) * sim_weight.unsqueeze(dim=-1), dim=1)\n",
    "    pred_labels = pred_scores.argsort(dim=-1, descending=True)\n",
    "    return pred_labels\n",
    "\n",
    "\n",
    "class BenchmarkModule(pl.LightningModule):\n",
    "    \"\"\"A PyTorch Lightning Module for automated kNN callback\n",
    "    \n",
    "    At the end of every training epoch we create a feature bank by inferencing\n",
    "    the backbone on the dataloader passed to the module. \n",
    "    At every validation step we predict features on the validation data.\n",
    "    After all predictions on validation data (validation_epoch_end) we evaluate\n",
    "    the predictions on a kNN classifier on the validation data using the \n",
    "    feature_bank features from the train data.\n",
    "    We can access the highest accuracy during a kNN prediction using the \n",
    "    max_accuracy attribute.\n",
    "    \"\"\"\n",
    "    def __init__(self, dataloader_kNN, gpus, classes, knn_k, knn_t):\n",
    "        super().__init__()\n",
    "        self.backbone = nn.Module()\n",
    "        self.max_accuracy = 0.0\n",
    "        self.dataloader_kNN = dataloader_kNN\n",
    "        self.gpus = gpus\n",
    "        self.classes = classes\n",
    "        self.knn_k = knn_k\n",
    "        self.knn_t = knn_t\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        # update feature bank at the end of each training epoch\n",
    "        self.backbone.eval()\n",
    "        self.feature_bank = []\n",
    "        self.targets_bank = []\n",
    "        with torch.no_grad():\n",
    "            for data in self.dataloader_kNN:\n",
    "                img, target, _ = data\n",
    "                if self.gpus > 0:\n",
    "                    img = img[0].cuda()\n",
    "                    target = target[0].cuda()\n",
    "                feature = self.backbone(img).squeeze()\n",
    "                feature = F.normalize(feature, dim=1)\n",
    "                self.feature_bank.append(feature)\n",
    "                self.targets_bank.append(target)\n",
    "#         print(\"targets_bank:\",self.targets_bank)\n",
    "#         self.feature_bank = torch.cat(self.feature_bank).t().contiguous()\n",
    "#         self.targets_bank = torch.cat(self.targets_bank).t().contiguous()\n",
    "        self.backbone.train()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # we can only do kNN predictions once we have a feature bank\n",
    "        if hasattr(self, 'feature_bank') and hasattr(self, 'targets_bank'):\n",
    "            images, targets, _ = batch\n",
    "            feature = self.backbone(images).squeeze()\n",
    "            feature = F.normalize(feature, dim=1)\n",
    "            pred_labels = knn_predict(feature, self.feature_bank, self.targets_bank, self.classes, self.knn_k, self.knn_t)\n",
    "            num = images.size(0)\n",
    "            top1 = (pred_labels[:, 0] == targets).float().sum().item()\n",
    "            return (num, top1)\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        if outputs:\n",
    "            total_num = 0\n",
    "            total_top1 = 0.\n",
    "            for (num, top1) in outputs:\n",
    "                total_num += num\n",
    "                total_top1 += top1\n",
    "            acc = float(total_top1 / total_num)\n",
    "            if acc > self.max_accuracy:\n",
    "                self.max_accuracy = acc\n",
    "            self.log('kNN_accuracy', acc * 100.0, prog_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5e07db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_byol_mlp(num_ftrs: int, hidden_dim: int, out_dim: int):\n",
    "    \"\"\"Returns a 2-layer MLP with batch norm on the hidden layer.\n",
    "    Reference (12.03.2021)\n",
    "    https://arxiv.org/abs/2006.07733\n",
    "    \"\"\"\n",
    "    modules = [\n",
    "        nn.Linear(num_ftrs, hidden_dim),\n",
    "        nn.BatchNorm1d(hidden_dim),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(hidden_dim, out_dim)\n",
    "    ]\n",
    "    return nn.Sequential(*modules)\n",
    "\n",
    "\n",
    "class BYOL(nn.Module, _MomentumEncoderMixin):\n",
    "    \"\"\"Implementation of the BYOL architecture.\n",
    "    Attributes:\n",
    "        backbone:\n",
    "            Backbone model to extract features from images.\n",
    "        num_ftrs:\n",
    "            Dimension of the embedding (before the projection mlp).\n",
    "        hidden_dim:\n",
    "            Dimension of the hidden layer in the projection and prediction mlp.\n",
    "        out_dim:\n",
    "            Dimension of the output (after the projection/prediction mlp).\n",
    "        m:\n",
    "            Momentum for the momentum update of encoder.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 # TODO adapt parameters according to paper\n",
    "                 backbone: nn.Module,\n",
    "                 num_ftrs: int = 512,\n",
    "                 hidden_dim: int = 4096,\n",
    "                 out_dim: int = 256,\n",
    "                 m: float = 0.999):\n",
    "\n",
    "        super(BYOL, self).__init__()\n",
    "\n",
    "        self.backbone = backbone\n",
    "        self.projection_head = _get_byol_mlp(num_ftrs, hidden_dim, out_dim)\n",
    "        self.prediction_head = _get_byol_mlp(out_dim, hidden_dim, out_dim)\n",
    "        self.momentum_backbone = None\n",
    "        self.momentum_projection_head = None\n",
    "\n",
    "        self._init_momentum_encoder()\n",
    "        self.m = m\n",
    "\n",
    "    def _forward(self,\n",
    "                x0: torch.Tensor,\n",
    "                x1: torch.Tensor = None,\n",
    "                return_features: bool = False):\n",
    "        \"\"\"Forward pass through the encoder and the momentum encoder.\n",
    "        Performs the momentum update, extracts features with the backbone and\n",
    "        applies the projection (and prediciton) head to the output space. If\n",
    "        x1 is None, only x0 will be processed otherwise, x0 is processed with\n",
    "        the encoder and x1 with the momentum encoder.\n",
    "        Args:\n",
    "            x0:\n",
    "                Tensor of shape bsz x channels x W x H.\n",
    "            x1:\n",
    "                Tensor of shape bsz x channels x W x H.\n",
    "            return_features:\n",
    "                Whether or not to return the intermediate features backbone(x).\n",
    "        Returns:\n",
    "            The output proejction of x0 and (if x1 is not None) the output \n",
    "            projection of x1. If return_features is True, the output for each x \n",
    "            is a tuple (out, f) where f are the features before the projection\n",
    "            head.\n",
    "        \n",
    "        Examples:\n",
    "            >>> # single input, single output\n",
    "            >>> out = model._forward(x)\n",
    "            >>>\n",
    "            >>> # single input with return_features=True\n",
    "            >>> out, f = model._forward(x, return_features=True)\n",
    "            >>>\n",
    "            >>> # two inputs, two outputs\n",
    "            >>> out0, out1 = model._forward(x0, x1)\n",
    "            >>>\n",
    "            >>> # two inputs two outputs with return_features=True\n",
    "            >>> (out0, f0), (out1, f1) = model._forward(x0, x1, return_features=True)\n",
    "        \"\"\"\n",
    "\n",
    "        self._momentum_update(self.m)\n",
    "\n",
    "        # forward pass of first input x0\n",
    "        f0 = self.backbone(x0).squeeze()\n",
    "        z0 = self.projection_head(f0)\n",
    "        out0 = self.prediction_head(z0)\n",
    "\n",
    "        # append features if requested\n",
    "        if return_features:\n",
    "            out0 = (out0, f0)\n",
    "\n",
    "        if x1 is None:\n",
    "            return out0\n",
    "\n",
    "        # forward pass of second input x1\n",
    "        with torch.no_grad():\n",
    "\n",
    "            f1 = self.momentum_backbone(x1).squeeze()\n",
    "            out1 = self.momentum_projection_head(f1)\n",
    "        \n",
    "            if return_features:\n",
    "                out1 = (out1, f1)\n",
    "        \n",
    "        return out0, out1\n",
    "\n",
    "    def forward(self,\n",
    "                x0: torch.Tensor,\n",
    "                x1: torch.Tensor = None,\n",
    "                return_features: bool = False\n",
    "                ):\n",
    "        \"\"\"Symmetrizes the forward pass (see _forward).\n",
    "        Performs two forward passes, once where x0 is passed through the encoder\n",
    "        and x1 through the momentum encoder and once the other way around.\n",
    "        Args:\n",
    "            x0:\n",
    "                Tensor of shape bsz x channels x W x H.\n",
    "            x1:\n",
    "                Tensor of shape bsz x channels x W x H.\n",
    "        Returns: TODO\n",
    "        \"\"\"\n",
    "        p0, z1 = self._forward(x0, x1, return_features=return_features)\n",
    "        p1, z0 = self._forward(x1, x0, return_features=return_features)\n",
    "\n",
    "        return (z0, p0), (z1, p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "961b254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BYOLModule(BenchmarkModule):\n",
    "    def __init__(self, dataloader, gpus, classes, knn_k, knn_t):\n",
    "        super().__init__(dataloader, gpus, classes, knn_k, knn_t)\n",
    "        # create a ResNet backbone and remove the classification head\n",
    "        resnet = lightly.models.ResNetGenerator('resnet-34')\n",
    "        self.backbone = nn.Sequential(\n",
    "            *list(resnet.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "        # create a simsiam model based on ResNet\n",
    "        # note that bartontwins has the same architecture\n",
    "        self.resnet_byol = BYOL(self.backbone, num_ftrs=512, hidden_dim=1024, out_dim=1024,m=0.996)\n",
    "        self.criterion = lightly.loss.SymNegCosineSimilarityLoss()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        self.resnet_simsiam(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        (x0, x1), _, _ = batch\n",
    "        y0, y1 = self.resnet_byol(x0, x1)\n",
    "        # symmetrize the outputs of byol and calculate the loss\n",
    "        loss = self.criterion(y0, y1)\n",
    "        self.log('train_loss_ssl', loss)\n",
    "        return loss\n",
    "\n",
    "    # learning rate warm-up\n",
    "    def optimizer_steps(self,\n",
    "                        epoch=None,\n",
    "                        batch_idx=None,\n",
    "                        optimizer=None,\n",
    "                        optimizer_idx=None,\n",
    "                        optimizer_closure=None,\n",
    "                        on_tpu=None,\n",
    "                        using_native_amp=None,\n",
    "                        using_lbfgs=None):        \n",
    "\n",
    "        # learning rate warmup\n",
    "        if self.trainer.global_step < 1000:\n",
    "            lr_scale = min(1., float(self.trainer.global_step + 1) / 1000.)\n",
    "            for pg in optimizer.param_groups:\n",
    "                pg['lr'] = lr_scale * 2e-2 * 512 / 256\n",
    "\n",
    "        # update params\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        lr = 2e-2 * 512 / 256 # linear scaling of lr\n",
    "        optim = torch.optim.SGD(self.resnet_byol.parameters(), lr=lr,\n",
    "                                momentum=0.9, weight_decay=5e-4)\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optim, 800)\n",
    "        return [optim], [scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3dd3217a",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "\n",
    "# model = BYOLModule(dataloader, 1, 800, 200, 0.1)\n",
    "# checkpoint_callback = ModelCheckpoint(monitor='train_loss_ssl', save_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79bc786",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# trainer = pl.Trainer(gpus=1, deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/nr2229/BYOL/byol-resent34', profiler=\"simple\",\n",
    "#                      precision=16, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)\n",
    "# trainer.fit(model, train_dataloader=dataloader) \n",
    "\n",
    "\n",
    "\n",
    "# trainer.fit(\n",
    "#     model,\n",
    "#     train_dataloader=dataloader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae4c3bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "byol = BYOLModule.load_from_checkpoint(\"/scratch/nr2229/BYOL/byol-resent34-300Epochs/lightning_logs/version_6110740/checkpoints/last.ckpt\",dataloader=dataloader,gpus=1, classes=800, knn_k=200, knn_t=0.1)\n",
    "# byol = BYOLModule(dataloader=dataloader,gpus=1, classes=800, knn_k=200, knn_t=0.1)\n",
    "def expand_greyscale(t):\n",
    "    return t.expand(3, -1, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9d23864d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "/ext3/miniconda3/envs/dev/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name        | Type                       | Params\n",
      "-----------------------------------------------------------\n",
      "0 | backbone    | Sequential                 | 21.3 M\n",
      "1 | resnet_byol | BYOL                       | 47.8 M\n",
      "2 | criterion   | SymNegCosineSimilarityLoss | 0     \n",
      "-----------------------------------------------------------\n",
      "25.0 M    Trainable params\n",
      "22.9 M    Non-trainable params\n",
      "47.8 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/1000 [00:02<?, ?it/s] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/envs/dev/lib/python3.8/site-packages/pytorch_lightning/utilities/distributed.py:50: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action              \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "Total               \t|  -              \t|_              \t|  4.8598         \t|  100 %          \t|\n",
      "---------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch  \t|  2.0659         \t|1              \t|  2.0659         \t|  42.511         \t|\n",
      "on_train_end        \t|  0.00097845     \t|1              \t|  0.00097845     \t|  0.020134       \t|\n",
      "on_epoch_start      \t|  0.00057626     \t|1              \t|  0.00057626     \t|  0.011858       \t|\n",
      "on_train_start      \t|  0.0003744      \t|1              \t|  0.0003744      \t|  0.0077039      \t|\n",
      "cache_result        \t|  6.3693e-06     \t|4              \t|  2.5477e-05     \t|  0.00052425     \t|\n",
      "on_fit_start        \t|  2.1257e-05     \t|1              \t|  2.1257e-05     \t|  0.00043739     \t|\n",
      "on_train_epoch_start\t|  7.9554e-06     \t|1              \t|  7.9554e-06     \t|  0.0001637      \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_callback = ModelCheckpoint(monitor='train_loss_ssl', save_last=True)\n",
    "\n",
    "trainer = pl.Trainer(gpus=1, deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/nr2229/BYOL/byol-resent34-testing', profiler=\"simple\",\n",
    "                     precision=16, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)\n",
    "trainer.fit(byol, train_dataloader=dataloader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a670645",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUImageNetDataModule(pl.LightningDataModule):\n",
    "  \n",
    "    def train_dataloader(self):\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(expand_greyscale),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        trainset = CustomDataset(root='/dataset', split=\"train\", transform=train_transform)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        eval_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        evalset = CustomDataset(root='/dataset', split=\"val\", transform=eval_transform)\n",
    "        eval_loader = torch.utils.data.DataLoader(evalset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return eval_loader\n",
    "    \n",
    "    def ssl_train_dataloader(self, batch_size):\n",
    "        ssl_train_transform = transforms.Compose([\n",
    "#             transforms.Resize((96,96)),\n",
    "            transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Lambda(expand_greyscale),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        unlabeled_dataset = CustomDataset(root='/dataset', split='unlabeled', transform=ssl_train_transform)\n",
    "        unlabeled_dataloader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return unlabeled_dataloader\n",
    "        \n",
    "    def ssl_val_dataloader(self, batch_size):\n",
    "        ssl_eval_transform = transforms.Compose([\n",
    "#             transforms.Resize((96,96)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        val_dataset = CustomDataset(root='/dataset', split='val', transform=ssl_eval_transform)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d371e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYUImageNetDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "07defea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclr.modules.identity import Identity\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "class ResNetClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()  \n",
    "        resnet = lightly.models.ResNetGenerator('resnet-34')\n",
    "#         resnet = lightly.models.ResNetGenerator('resnet-34')\n",
    "        self.encoder = nn.Sequential(\n",
    "            *list(resnet.children())[:-1],\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "        )\n",
    "#         self.encoder.fc = nn.Identity()\n",
    "        states = byol.backbone.state_dict()\n",
    "        self.encoder.load_state_dict(states)\n",
    "        self.lastLayer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(p=0.1),\n",
    "            torch.nn.Linear(1024, 800),\n",
    "        )\n",
    "#         self.lastLayer = torch.nn.Linear(512, 800)\n",
    "        for layer in self.lastLayer.modules():\n",
    "           if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.01)\n",
    "                layer.bias.data.zero_()\n",
    "        \n",
    "        self.param_groups = [dict(params=self.lastLayer.parameters(), lr=0.01)]\n",
    "        self.param_groups.append(dict(params=byol.parameters(), lr=0.0005))\n",
    "        \n",
    "        self.criterion=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "#         resnet = lightly.models.ResNetGenerator('resnet-34')\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             *list(resnet.children())[:-1],\n",
    "#             nn.AdaptiveAvgPool2d(1),\n",
    "#         )\n",
    "#         states = byol.backbone.state_dict()\n",
    "#         self.encoder.load_state_dict(states)\n",
    "# #         self.encoder.load_state_dict(torch.load(os.path.join('/scratch/nr2229/barlow-34/','version_5956041_backbone.pth')))\n",
    "#         self.lastLayer = torch.nn.Linear(512, 800)\n",
    "#         self.criterion=torch.nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(self.encoder(x), 1)\n",
    "#         print(x.shape)\n",
    "#         x = self.encoder(x)\n",
    "#         print(x.shape)\n",
    "#         x = self.relu(self.projector(x))\n",
    "        x = self.lastLayer(x)\n",
    "        return x\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "#         data, label = batch\n",
    "        data = batch[0]\n",
    "        label = batch[1]\n",
    "        classProbs = self.forward(data)\n",
    "        loss = self.criterion(classProbs, label)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "#         x, y = batch\n",
    "        x = batch[0]\n",
    "        y = batch[1]\n",
    "        out = self.forward(x)\n",
    "        logits = F.log_softmax(out, dim=-1)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.param_groups, weight_decay = 1e-5)\n",
    "#         optimizer = optim.SGD(self.param_groups, 0, momentum=0.9, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS, verbose=True)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}\n",
    "#     def forward(self, x):\n",
    "#         x = torch.flatten(self.encoder(x), 1)\n",
    "# #         print(\"shape1\",x.shape)\n",
    "#         x = self.lastLayer(x)\n",
    "# #         print(\"shape2\",x.shape)\n",
    "#         return x\n",
    "    \n",
    "#     def training_step(self, batch, batch_idx):\n",
    "# #         data, label = batch\n",
    "#         data = batch[0]\n",
    "#         label = batch[1]\n",
    "#         classProbs = self.forward(data)\n",
    "#         loss = self.criterion(classProbs, label)\n",
    "#         self.log('train_loss', loss)\n",
    "#         return loss\n",
    "    \n",
    "#     def validation_step(self,batch,batch_idx):\n",
    "# #         print(\"batch shape:\", batch)\n",
    "#         data = batch[0]\n",
    "#         label = batch[1]\n",
    "#         classProbs = self.forward(data)\n",
    "#         loss = self.criterion(classProbs, label)\n",
    "#         self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "#         return { 'val_loss' : loss, 'prediction' : classProbs, 'target' : label }\n",
    "    \n",
    "#     def configure_optimizers(self):\n",
    "#         optimizer = torch.optim.Adam(self.parameters())\n",
    "#         scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "#         return ({'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d125e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200\n",
    "classifier = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ccee0ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_last=True)\n",
    "classifier_trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/nr2229/classifier-' + 'byol-resnet34-lightly', profiler=\"simple\",\n",
    "                     limit_val_batches= 0.5, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e424a480",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | encoder   | Sequential       | 21.3 M\n",
      "1 | lastLayer | Sequential       | 1.3 M \n",
      "2 | criterion | CrossEntropyLoss | 0     \n",
      "-----------------------------------------------\n",
      "22.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "22.6 M    Total params\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusting learning rate of group 0 to 1.0000e-02.\n",
      "Adjusting learning rate of group 1 to 5.0000e-04.\n",
      "Epoch 0:  67%|██████▋   | 400/600 [01:36<00:48,  4.13it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 0:  67%|██████▋   | 402/600 [01:37<00:47,  4.14it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  67%|██████▋   | 404/600 [01:37<00:47,  4.15it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  68%|██████▊   | 406/600 [01:37<00:46,  4.17it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  68%|██████▊   | 408/600 [01:37<00:45,  4.18it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  68%|██████▊   | 410/600 [01:37<00:45,  4.20it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  69%|██████▊   | 412/600 [01:37<00:44,  4.21it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  69%|██████▉   | 414/600 [01:37<00:44,  4.22it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  69%|██████▉   | 416/600 [01:38<00:43,  4.24it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  70%|██████▉   | 418/600 [01:38<00:42,  4.25it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  70%|███████   | 420/600 [01:38<00:42,  4.27it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  70%|███████   | 422/600 [01:38<00:41,  4.28it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  71%|███████   | 424/600 [01:38<00:40,  4.30it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  71%|███████   | 426/600 [01:38<00:40,  4.31it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  71%|███████▏  | 428/600 [01:38<00:39,  4.33it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  72%|███████▏  | 430/600 [01:39<00:39,  4.34it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  72%|███████▏  | 432/600 [01:39<00:38,  4.36it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  72%|███████▏  | 434/600 [01:39<00:37,  4.37it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  73%|███████▎  | 436/600 [01:39<00:37,  4.39it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  73%|███████▎  | 438/600 [01:39<00:36,  4.40it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  73%|███████▎  | 440/600 [01:39<00:36,  4.41it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  74%|███████▎  | 442/600 [01:39<00:35,  4.43it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  74%|███████▍  | 444/600 [01:39<00:35,  4.44it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  74%|███████▍  | 446/600 [01:40<00:34,  4.46it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  75%|███████▍  | 448/600 [01:40<00:34,  4.47it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  75%|███████▌  | 450/600 [01:40<00:33,  4.48it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  75%|███████▌  | 452/600 [01:40<00:32,  4.50it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  76%|███████▌  | 454/600 [01:40<00:32,  4.51it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  76%|███████▌  | 456/600 [01:40<00:31,  4.53it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  76%|███████▋  | 458/600 [01:40<00:31,  4.54it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  77%|███████▋  | 460/600 [01:40<00:30,  4.55it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  77%|███████▋  | 462/600 [01:41<00:30,  4.57it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  77%|███████▋  | 464/600 [01:41<00:29,  4.58it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  78%|███████▊  | 466/600 [01:41<00:29,  4.60it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  78%|███████▊  | 468/600 [01:41<00:28,  4.61it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  78%|███████▊  | 470/600 [01:41<00:28,  4.62it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  79%|███████▊  | 472/600 [01:41<00:27,  4.64it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  79%|███████▉  | 474/600 [01:41<00:27,  4.65it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  79%|███████▉  | 476/600 [01:42<00:26,  4.66it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  80%|███████▉  | 478/600 [01:42<00:26,  4.68it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  80%|████████  | 480/600 [01:42<00:25,  4.69it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  80%|████████  | 482/600 [01:42<00:25,  4.71it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  81%|████████  | 484/600 [01:42<00:24,  4.72it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  81%|████████  | 486/600 [01:42<00:24,  4.73it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  81%|████████▏ | 488/600 [01:42<00:23,  4.75it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  82%|████████▏ | 490/600 [01:42<00:23,  4.76it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  82%|████████▏ | 492/600 [01:43<00:22,  4.77it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  82%|████████▏ | 494/600 [01:43<00:22,  4.79it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  83%|████████▎ | 496/600 [01:43<00:21,  4.80it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  83%|████████▎ | 498/600 [01:43<00:21,  4.81it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  83%|████████▎ | 500/600 [01:43<00:20,  4.83it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  84%|████████▎ | 502/600 [01:43<00:20,  4.84it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  84%|████████▍ | 504/600 [01:43<00:19,  4.85it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  84%|████████▍ | 506/600 [01:44<00:19,  4.86it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  85%|████████▍ | 508/600 [01:44<00:18,  4.88it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  85%|████████▌ | 510/600 [01:44<00:18,  4.89it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  85%|████████▌ | 512/600 [01:44<00:17,  4.90it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  86%|████████▌ | 514/600 [01:44<00:17,  4.92it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  86%|████████▌ | 516/600 [01:44<00:17,  4.93it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  86%|████████▋ | 518/600 [01:44<00:16,  4.94it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  87%|████████▋ | 520/600 [01:44<00:16,  4.95it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  87%|████████▋ | 522/600 [01:45<00:15,  4.97it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  87%|████████▋ | 524/600 [01:45<00:15,  4.98it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  88%|████████▊ | 526/600 [01:45<00:14,  4.99it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  88%|████████▊ | 528/600 [01:45<00:14,  5.01it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  88%|████████▊ | 530/600 [01:45<00:13,  5.02it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  89%|████████▊ | 532/600 [01:45<00:13,  5.03it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  89%|████████▉ | 534/600 [01:45<00:13,  5.04it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  89%|████████▉ | 536/600 [01:45<00:12,  5.06it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  90%|████████▉ | 538/600 [01:46<00:12,  5.07it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  90%|█████████ | 540/600 [01:46<00:11,  5.08it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  90%|█████████ | 542/600 [01:46<00:11,  5.09it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  91%|█████████ | 544/600 [01:46<00:10,  5.11it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  91%|█████████ | 546/600 [01:46<00:10,  5.12it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  91%|█████████▏| 548/600 [01:46<00:10,  5.13it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  92%|█████████▏| 550/600 [01:46<00:09,  5.14it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  92%|█████████▏| 552/600 [01:47<00:09,  5.16it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  92%|█████████▏| 554/600 [01:47<00:08,  5.17it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  93%|█████████▎| 556/600 [01:47<00:08,  5.18it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  93%|█████████▎| 558/600 [01:47<00:08,  5.19it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  93%|█████████▎| 560/600 [01:47<00:07,  5.21it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  94%|█████████▎| 562/600 [01:47<00:07,  5.22it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  94%|█████████▍| 564/600 [01:47<00:06,  5.23it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  94%|█████████▍| 566/600 [01:47<00:06,  5.24it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  95%|█████████▍| 568/600 [01:48<00:06,  5.26it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  95%|█████████▌| 570/600 [01:48<00:05,  5.27it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  95%|█████████▌| 572/600 [01:48<00:05,  5.28it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  96%|█████████▌| 574/600 [01:48<00:04,  5.29it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  96%|█████████▌| 576/600 [01:48<00:04,  5.30it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  96%|█████████▋| 578/600 [01:48<00:04,  5.32it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  97%|█████████▋| 580/600 [01:48<00:03,  5.33it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  97%|█████████▋| 582/600 [01:48<00:03,  5.34it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  97%|█████████▋| 584/600 [01:49<00:02,  5.35it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  98%|█████████▊| 586/600 [01:49<00:02,  5.36it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  98%|█████████▊| 588/600 [01:49<00:02,  5.38it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  98%|█████████▊| 590/600 [01:49<00:01,  5.39it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  99%|█████████▊| 592/600 [01:49<00:01,  5.40it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  99%|█████████▉| 594/600 [01:49<00:01,  5.41it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0:  99%|█████████▉| 596/600 [01:49<00:00,  5.42it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0: 100%|█████████▉| 598/600 [01:50<00:00,  5.43it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]\n",
      "Epoch 0: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=5.32, v_num=18, val_loss=6.68, val_acc=0.0625]Adjusting learning rate of group 0 to 9.9994e-03.\n",
      "Adjusting learning rate of group 1 to 4.9997e-04.\n",
      "Epoch 0: 100%|██████████| 600/600 [01:50<00:00,  5.42it/s, loss=5.32, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 1:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]\n",
      "Epoch 1: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.88, v_num=18, val_loss=5.03, val_acc=0.0578]Adjusting learning rate of group 0 to 9.9975e-03.\n",
      "Adjusting learning rate of group 1 to 4.9988e-04.\n",
      "Epoch 1: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.88, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 2:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]\n",
      "Epoch 2: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.55, v_num=18, val_loss=4.57, val_acc=0.0925]Adjusting learning rate of group 0 to 9.9944e-03.\n",
      "Adjusting learning rate of group 1 to 4.9972e-04.\n",
      "Epoch 2: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.55, v_num=18, val_loss=4.35, val_acc=0.123] \n",
      "Epoch 3:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 3:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]\n",
      "Epoch 3: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.46, v_num=18, val_loss=4.35, val_acc=0.123]Adjusting learning rate of group 0 to 9.9901e-03.\n",
      "Adjusting learning rate of group 1 to 4.9951e-04.\n",
      "Epoch 3: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.46, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 4:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]\n",
      "Epoch 4: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.31, v_num=18, val_loss=4.23, val_acc=0.132]Adjusting learning rate of group 0 to 9.9846e-03.\n",
      "Adjusting learning rate of group 1 to 4.9923e-04.\n",
      "Epoch 4: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.31, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 5:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]\n",
      "Epoch 5: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.29, v_num=18, val_loss=4.16, val_acc=0.146]Adjusting learning rate of group 0 to 9.9778e-03.\n",
      "Adjusting learning rate of group 1 to 4.9889e-04.\n",
      "Epoch 5: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.29, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 6:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]\n",
      "Epoch 6: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.17, v_num=18, val_loss=4.11, val_acc=0.153]Adjusting learning rate of group 0 to 9.9698e-03.\n",
      "Adjusting learning rate of group 1 to 4.9849e-04.\n",
      "Epoch 6: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.17, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 7:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]\n",
      "Epoch 7: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.38, v_num=18, val_loss=4.08, val_acc=0.154]Adjusting learning rate of group 0 to 9.9606e-03.\n",
      "Adjusting learning rate of group 1 to 4.9803e-04.\n",
      "Epoch 7: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.38, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 8:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  73%|███████▎  | 438/600 [01:38<00:36,  4.42it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]\n",
      "Epoch 8: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.15, v_num=18, val_loss=4.05, val_acc=0.156]Adjusting learning rate of group 0 to 9.9501e-03.\n",
      "Adjusting learning rate of group 1 to 4.9751e-04.\n",
      "Epoch 8: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.15, v_num=18, val_loss=4, val_acc=0.17]    \n",
      "Epoch 9:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 9:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]\n",
      "Epoch 9: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.13, v_num=18, val_loss=4, val_acc=0.17]Adjusting learning rate of group 0 to 9.9384e-03.\n",
      "Adjusting learning rate of group 1 to 4.9692e-04.\n",
      "Epoch 9: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.13, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 10:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  73%|███████▎  | 438/600 [01:38<00:36,  4.42it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]\n",
      "Epoch 10: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.08, v_num=18, val_loss=4.02, val_acc=0.167]Adjusting learning rate of group 0 to 9.9255e-03.\n",
      "Adjusting learning rate of group 1 to 4.9628e-04.\n",
      "Epoch 10: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.08, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 11:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]\n",
      "Epoch 11: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.167]Adjusting learning rate of group 0 to 9.9114e-03.\n",
      "Adjusting learning rate of group 1 to 4.9557e-04.\n",
      "Epoch 11: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.12, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 12:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]\n",
      "Epoch 12: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.06, v_num=18, val_loss=3.97, val_acc=0.175]Adjusting learning rate of group 0 to 9.8961e-03.\n",
      "Adjusting learning rate of group 1 to 4.9481e-04.\n",
      "Epoch 12: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.06, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 13:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  83%|████████▎ | 498/600 [01:43<00:21,  4.83it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]\n",
      "Epoch 13: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.04, v_num=18, val_loss=3.94, val_acc=0.178]Adjusting learning rate of group 0 to 9.8796e-03.\n",
      "Adjusting learning rate of group 1 to 4.9398e-04.\n",
      "Epoch 13: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.04, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 14:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]\n",
      "Epoch 14: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.07, v_num=18, val_loss=3.96, val_acc=0.174]Adjusting learning rate of group 0 to 9.8618e-03.\n",
      "Adjusting learning rate of group 1 to 4.9309e-04.\n",
      "Epoch 14: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4.07, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 15:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]\n",
      "Epoch 15: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.176]Adjusting learning rate of group 0 to 9.8429e-03.\n",
      "Adjusting learning rate of group 1 to 4.9215e-04.\n",
      "Epoch 15: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 16:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]\n",
      "Epoch 16: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.97, v_num=18, val_loss=3.94, val_acc=0.181]Adjusting learning rate of group 0 to 9.8228e-03.\n",
      "Adjusting learning rate of group 1 to 4.9114e-04.\n",
      "Epoch 16: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.97, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 17:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]\n",
      "Epoch 17: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.06, v_num=18, val_loss=3.93, val_acc=0.181]Adjusting learning rate of group 0 to 9.8015e-03.\n",
      "Adjusting learning rate of group 1 to 4.9007e-04.\n",
      "Epoch 17: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.06, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 18:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]\n",
      "Epoch 18: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.183]Adjusting learning rate of group 0 to 9.7790e-03.\n",
      "Adjusting learning rate of group 1 to 4.8895e-04.\n",
      "Epoch 18: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=3.92, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 19:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  68%|██████▊   | 406/600 [01:37<00:46,  4.19it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  70%|██████▉   | 418/600 [01:37<00:42,  4.27it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  75%|███████▌  | 452/600 [01:40<00:32,  4.52it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  82%|████████▏ | 492/600 [01:42<00:22,  4.79it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  83%|████████▎ | 498/600 [01:43<00:21,  4.83it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  87%|████████▋ | 524/600 [01:44<00:15,  5.00it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  91%|█████████ | 544/600 [01:46<00:10,  5.13it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]\n",
      "Epoch 19: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.187]Adjusting learning rate of group 0 to 9.7553e-03.\n",
      "Adjusting learning rate of group 1 to 4.8776e-04.\n",
      "Epoch 19: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=4.03, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 20:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]\n",
      "Epoch 20: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.98, v_num=18, val_loss=3.88, val_acc=0.189]Adjusting learning rate of group 0 to 9.7304e-03.\n",
      "Adjusting learning rate of group 1 to 4.8652e-04.\n",
      "Epoch 20: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.98, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 21:  67%|██████▋   | 402/600 [01:36<00:47,  4.15it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  67%|██████▋   | 404/600 [01:36<00:47,  4.17it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  68%|██████▊   | 406/600 [01:37<00:46,  4.18it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  68%|██████▊   | 410/600 [01:37<00:45,  4.21it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  69%|██████▉   | 414/600 [01:37<00:43,  4.24it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  70%|██████▉   | 418/600 [01:37<00:42,  4.27it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  75%|███████▌  | 452/600 [01:40<00:32,  4.52it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  78%|███████▊  | 470/600 [01:41<00:27,  4.64it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  82%|████████▏ | 492/600 [01:42<00:22,  4.79it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  83%|████████▎ | 498/600 [01:43<00:21,  4.83it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  87%|████████▋ | 524/600 [01:44<00:15,  5.00it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  91%|█████████ | 544/600 [01:46<00:10,  5.13it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  97%|█████████▋| 582/600 [01:48<00:03,  5.36it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  98%|█████████▊| 590/600 [01:49<00:01,  5.41it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]\n",
      "Epoch 21: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.89, v_num=18, val_loss=3.86, val_acc=0.188]Adjusting learning rate of group 0 to 9.7044e-03.\n",
      "Adjusting learning rate of group 1 to 4.8522e-04.\n",
      "Epoch 21: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.89, v_num=18, val_loss=3.89, val_acc=0.19] \n",
      "Epoch 22:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]   \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 22:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]\n",
      "Epoch 22: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4, v_num=18, val_loss=3.89, val_acc=0.19]Adjusting learning rate of group 0 to 9.6772e-03.\n",
      "Adjusting learning rate of group 1 to 4.8386e-04.\n",
      "Epoch 22: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=4, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 23:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  70%|██████▉   | 418/600 [01:37<00:42,  4.27it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  75%|███████▌  | 452/600 [01:40<00:32,  4.52it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  82%|████████▏ | 492/600 [01:42<00:22,  4.79it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  83%|████████▎ | 498/600 [01:42<00:21,  4.83it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]\n",
      "Epoch 23: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.98, v_num=18, val_loss=3.85, val_acc=0.194]Adjusting learning rate of group 0 to 9.6489e-03.\n",
      "Adjusting learning rate of group 1 to 4.8244e-04.\n",
      "Epoch 23: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.98, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 24:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]\n",
      "Epoch 24: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.99, v_num=18, val_loss=3.86, val_acc=0.192]Adjusting learning rate of group 0 to 9.6194e-03.\n",
      "Adjusting learning rate of group 1 to 4.8097e-04.\n",
      "Epoch 24: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.99, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 25:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 25: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.95, v_num=18, val_loss=3.85, val_acc=0.193]Adjusting learning rate of group 0 to 9.5888e-03.\n",
      "Adjusting learning rate of group 1 to 4.7944e-04.\n",
      "Epoch 25: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=3.95, v_num=18, val_loss=3.82, val_acc=0.2]  \n",
      "Epoch 26:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 26:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  73%|███████▎  | 438/600 [01:38<00:36,  4.42it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  81%|████████  | 484/600 [01:42<00:24,  4.75it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]\n",
      "Epoch 26: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.92, v_num=18, val_loss=3.82, val_acc=0.2]Adjusting learning rate of group 0 to 9.5570e-03.\n",
      "Adjusting learning rate of group 1 to 4.7785e-04.\n",
      "Epoch 26: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.92, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 27:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]\n",
      "Epoch 27: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.99, v_num=18, val_loss=3.89, val_acc=0.192]Adjusting learning rate of group 0 to 9.5241e-03.\n",
      "Adjusting learning rate of group 1 to 4.7621e-04.\n",
      "Epoch 27: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 28:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  68%|██████▊   | 410/600 [01:37<00:44,  4.22it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]\n",
      "Epoch 28: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=4.02, v_num=18, val_loss=3.85, val_acc=0.193]Adjusting learning rate of group 0 to 9.4901e-03.\n",
      "Adjusting learning rate of group 1 to 4.7451e-04.\n",
      "Epoch 28: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=4.02, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 29:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  70%|██████▉   | 418/600 [01:37<00:42,  4.27it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  75%|███████▌  | 452/600 [01:40<00:32,  4.52it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  82%|████████▏ | 492/600 [01:42<00:22,  4.79it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  83%|████████▎ | 498/600 [01:43<00:21,  4.83it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  87%|████████▋ | 524/600 [01:44<00:15,  5.00it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  91%|█████████ | 544/600 [01:46<00:10,  5.13it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  97%|█████████▋| 582/600 [01:48<00:03,  5.36it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  98%|█████████▊| 590/600 [01:49<00:01,  5.41it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]\n",
      "Epoch 29: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.99, v_num=18, val_loss=3.84, val_acc=0.194]Adjusting learning rate of group 0 to 9.4550e-03.\n",
      "Adjusting learning rate of group 1 to 4.7275e-04.\n",
      "Epoch 29: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.99, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 30:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  68%|██████▊   | 410/600 [01:37<00:44,  4.22it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  71%|███████   | 424/600 [01:37<00:40,  4.33it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  71%|███████▏  | 428/600 [01:38<00:39,  4.36it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  74%|███████▍  | 446/600 [01:39<00:34,  4.49it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  78%|███████▊  | 466/600 [01:40<00:28,  4.63it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  80%|████████  | 482/600 [01:41<00:24,  4.74it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  85%|████████▌ | 512/600 [01:43<00:17,  4.94it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  89%|████████▉ | 534/600 [01:45<00:12,  5.08it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  91%|█████████▏| 548/600 [01:46<00:10,  5.17it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  97%|█████████▋| 584/600 [01:48<00:02,  5.39it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 30: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.94, v_num=18, val_loss=3.83, val_acc=0.196]Adjusting learning rate of group 0 to 9.4188e-03.\n",
      "Adjusting learning rate of group 1 to 4.7094e-04.\n",
      "Epoch 30: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 31:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 31: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]Adjusting learning rate of group 0 to 9.3815e-03.\n",
      "Adjusting learning rate of group 1 to 4.6908e-04.\n",
      "Epoch 31: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.84, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 32:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  68%|██████▊   | 410/600 [01:37<00:44,  4.22it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  71%|███████   | 424/600 [01:37<00:40,  4.33it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  71%|███████▏  | 428/600 [01:38<00:39,  4.36it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  72%|███████▏  | 432/600 [01:38<00:38,  4.39it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  74%|███████▍  | 446/600 [01:39<00:34,  4.49it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  78%|███████▊  | 466/600 [01:40<00:28,  4.63it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  78%|███████▊  | 470/600 [01:40<00:27,  4.65it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  79%|███████▉  | 476/600 [01:41<00:26,  4.70it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  80%|████████  | 482/600 [01:41<00:24,  4.74it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  85%|████████▌ | 512/600 [01:43<00:17,  4.94it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  86%|████████▌ | 516/600 [01:43<00:16,  4.96it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  86%|████████▋ | 518/600 [01:44<00:16,  4.98it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  89%|████████▊ | 532/600 [01:45<00:13,  5.07it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  89%|████████▉ | 534/600 [01:45<00:12,  5.08it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  90%|█████████ | 540/600 [01:45<00:11,  5.12it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  91%|█████████▏| 548/600 [01:46<00:10,  5.17it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  93%|█████████▎| 556/600 [01:46<00:08,  5.22it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  94%|█████████▎| 562/600 [01:46<00:07,  5.25it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  94%|█████████▍| 564/600 [01:47<00:06,  5.27it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  96%|█████████▌| 574/600 [01:47<00:04,  5.33it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  97%|█████████▋| 584/600 [01:48<00:02,  5.39it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  99%|█████████▉| 594/600 [01:49<00:01,  5.45it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]\n",
      "Epoch 32: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.9, v_num=18, val_loss=3.82, val_acc=0.198]Adjusting learning rate of group 0 to 9.3432e-03.\n",
      "Adjusting learning rate of group 1 to 4.6716e-04.\n",
      "Epoch 32: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 33:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  98%|█████████▊| 590/600 [01:49<00:01,  5.41it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]\n",
      "Epoch 33: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.95, v_num=18, val_loss=3.83, val_acc=0.201]Adjusting learning rate of group 0 to 9.3037e-03.\n",
      "Adjusting learning rate of group 1 to 4.6519e-04.\n",
      "Epoch 33: 100%|██████████| 600/600 [01:50<00:00,  5.43it/s, loss=3.95, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 34:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  68%|██████▊   | 410/600 [01:37<00:44,  4.22it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  71%|███████   | 424/600 [01:37<00:40,  4.33it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  71%|███████▏  | 428/600 [01:38<00:39,  4.36it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  72%|███████▏  | 432/600 [01:38<00:38,  4.39it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  74%|███████▍  | 446/600 [01:39<00:34,  4.49it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  78%|███████▊  | 466/600 [01:40<00:28,  4.63it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  80%|████████  | 482/600 [01:41<00:24,  4.74it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  85%|████████▌ | 512/600 [01:43<00:17,  4.94it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  89%|████████▉ | 534/600 [01:45<00:12,  5.08it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  90%|█████████ | 540/600 [01:45<00:11,  5.12it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  91%|█████████▏| 548/600 [01:46<00:10,  5.17it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  96%|█████████▌| 574/600 [01:47<00:04,  5.33it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  97%|█████████▋| 584/600 [01:48<00:02,  5.39it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 34: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]Adjusting learning rate of group 0 to 9.2632e-03.\n",
      "Adjusting learning rate of group 1 to 4.6316e-04.\n",
      "Epoch 34: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.8, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 35:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]\n",
      "Epoch 35: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.197]Adjusting learning rate of group 0 to 9.2216e-03.\n",
      "Adjusting learning rate of group 1 to 4.6108e-04.\n",
      "Epoch 35: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.85, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 36:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]\n",
      "Epoch 36: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.199]Adjusting learning rate of group 0 to 9.1790e-03.\n",
      "Adjusting learning rate of group 1 to 4.5895e-04.\n",
      "Epoch 36: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.98, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 37:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]\n",
      "Epoch 37: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.81, v_num=18, val_loss=3.82, val_acc=0.194]Adjusting learning rate of group 0 to 9.1354e-03.\n",
      "Adjusting learning rate of group 1 to 4.5677e-04.\n",
      "Epoch 37: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=3.81, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 38:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]\n",
      "Epoch 38: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.89, v_num=18, val_loss=3.81, val_acc=0.204]Adjusting learning rate of group 0 to 9.0907e-03.\n",
      "Adjusting learning rate of group 1 to 4.5454e-04.\n",
      "Epoch 38: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.89, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 39:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]\n",
      "Epoch 39: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.94, v_num=18, val_loss=3.82, val_acc=0.202]Adjusting learning rate of group 0 to 9.0451e-03.\n",
      "Adjusting learning rate of group 1 to 4.5225e-04.\n",
      "Epoch 39: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.94, v_num=18, val_loss=3.81, val_acc=0.2]  \n",
      "Epoch 40:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 40:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  78%|███████▊  | 466/600 [01:40<00:28,  4.63it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 40: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.2]Adjusting learning rate of group 0 to 8.9984e-03.\n",
      "Adjusting learning rate of group 1 to 4.4992e-04.\n",
      "Epoch 40: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.8, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 41:  67%|██████▋   | 402/600 [01:36<00:47,  4.15it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  67%|██████▋   | 404/600 [01:36<00:47,  4.17it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  68%|██████▊   | 406/600 [01:37<00:46,  4.18it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  68%|██████▊   | 410/600 [01:37<00:45,  4.21it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  69%|██████▉   | 414/600 [01:37<00:43,  4.24it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  70%|██████▉   | 418/600 [01:37<00:42,  4.27it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  70%|███████   | 420/600 [01:38<00:42,  4.28it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  71%|███████   | 424/600 [01:38<00:40,  4.31it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  71%|███████▏  | 428/600 [01:38<00:39,  4.34it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  72%|███████▏  | 430/600 [01:38<00:39,  4.36it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  72%|███████▏  | 432/600 [01:38<00:38,  4.37it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  73%|███████▎  | 436/600 [01:39<00:37,  4.40it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  73%|███████▎  | 438/600 [01:39<00:36,  4.41it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  73%|███████▎  | 440/600 [01:39<00:36,  4.43it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  74%|███████▎  | 442/600 [01:39<00:35,  4.44it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  74%|███████▍  | 446/600 [01:39<00:34,  4.47it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  75%|███████▌  | 450/600 [01:39<00:33,  4.50it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  75%|███████▌  | 452/600 [01:40<00:32,  4.51it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  76%|███████▌  | 456/600 [01:40<00:31,  4.54it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  77%|███████▋  | 460/600 [01:40<00:30,  4.57it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  77%|███████▋  | 462/600 [01:40<00:30,  4.58it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  78%|███████▊  | 466/600 [01:41<00:29,  4.61it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  78%|███████▊  | 470/600 [01:41<00:28,  4.64it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  79%|███████▊  | 472/600 [01:41<00:27,  4.65it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  79%|███████▉  | 476/600 [01:41<00:26,  4.68it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  80%|███████▉  | 478/600 [01:41<00:25,  4.69it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  80%|████████  | 482/600 [01:42<00:24,  4.72it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  81%|████████  | 486/600 [01:42<00:24,  4.75it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  81%|████████▏ | 488/600 [01:42<00:23,  4.76it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  82%|████████▏ | 492/600 [01:42<00:22,  4.79it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  82%|████████▏ | 494/600 [01:42<00:22,  4.80it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  83%|████████▎ | 498/600 [01:43<00:21,  4.83it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  83%|████████▎ | 500/600 [01:43<00:20,  4.84it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  84%|████████▍ | 506/600 [01:43<00:19,  4.88it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  85%|████████▍ | 508/600 [01:43<00:18,  4.89it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  85%|████████▌ | 512/600 [01:44<00:17,  4.92it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  86%|████████▌ | 514/600 [01:44<00:17,  4.93it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  86%|████████▋ | 518/600 [01:44<00:16,  4.96it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  87%|████████▋ | 520/600 [01:44<00:16,  4.97it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  87%|████████▋ | 524/600 [01:44<00:15,  5.00it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  88%|████████▊ | 526/600 [01:44<00:14,  5.01it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  88%|████████▊ | 528/600 [01:45<00:14,  5.02it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  89%|████████▊ | 532/600 [01:45<00:13,  5.05it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  89%|████████▉ | 534/600 [01:45<00:13,  5.06it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  90%|█████████ | 540/600 [01:45<00:11,  5.10it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  90%|█████████ | 542/600 [01:46<00:11,  5.11it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  91%|█████████ | 544/600 [01:46<00:10,  5.13it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  91%|█████████▏| 548/600 [01:46<00:10,  5.15it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  92%|█████████▏| 550/600 [01:46<00:09,  5.16it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  93%|█████████▎| 556/600 [01:46<00:08,  5.20it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  93%|█████████▎| 558/600 [01:47<00:08,  5.21it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  93%|█████████▎| 560/600 [01:47<00:07,  5.22it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  94%|█████████▍| 564/600 [01:47<00:06,  5.25it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  94%|█████████▍| 566/600 [01:47<00:06,  5.26it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  95%|█████████▍| 568/600 [01:47<00:06,  5.27it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  96%|█████████▌| 574/600 [01:48<00:04,  5.31it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  96%|█████████▌| 576/600 [01:48<00:04,  5.32it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  96%|█████████▋| 578/600 [01:48<00:04,  5.33it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  97%|█████████▋| 582/600 [01:48<00:03,  5.36it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  97%|█████████▋| 584/600 [01:48<00:02,  5.37it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  98%|█████████▊| 586/600 [01:48<00:02,  5.38it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  98%|█████████▊| 588/600 [01:49<00:02,  5.39it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  98%|█████████▊| 590/600 [01:49<00:01,  5.41it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  99%|█████████▉| 594/600 [01:49<00:01,  5.43it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41:  99%|█████████▉| 596/600 [01:49<00:00,  5.44it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41: 100%|█████████▉| 598/600 [01:49<00:00,  5.45it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]\n",
      "Epoch 41: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.83, v_num=18, val_loss=3.81, val_acc=0.202]Adjusting learning rate of group 0 to 8.9508e-03.\n",
      "Adjusting learning rate of group 1 to 4.4754e-04.\n",
      "Epoch 41: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=3.83, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 42:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]\n",
      "Epoch 42: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.194]Adjusting learning rate of group 0 to 8.9022e-03.\n",
      "Adjusting learning rate of group 1 to 4.4511e-04.\n",
      "Epoch 42: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.9, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 43:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]\n",
      "Epoch 43: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.87, v_num=18, val_loss=3.83, val_acc=0.196]Adjusting learning rate of group 0 to 8.8526e-03.\n",
      "Adjusting learning rate of group 1 to 4.4263e-04.\n",
      "Epoch 43: 100%|██████████| 600/600 [01:50<00:00,  5.44it/s, loss=3.87, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 44:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 44: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.88, v_num=18, val_loss=3.79, val_acc=0.205]Adjusting learning rate of group 0 to 8.8020e-03.\n",
      "Adjusting learning rate of group 1 to 4.4010e-04.\n",
      "Epoch 44: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.88, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 45:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  70%|███████   | 422/600 [01:38<00:41,  4.30it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  81%|████████  | 486/600 [01:42<00:23,  4.75it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  84%|████████▍ | 504/600 [01:43<00:19,  4.87it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  95%|█████████▌| 572/600 [01:47<00:05,  5.30it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  98%|█████████▊| 590/600 [01:49<00:01,  5.41it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]\n",
      "Epoch 45: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.205]Adjusting learning rate of group 0 to 8.7506e-03.\n",
      "Adjusting learning rate of group 1 to 4.3753e-04.\n",
      "Epoch 45: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.79, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 46:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 46: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.82, v_num=18, val_loss=3.78, val_acc=0.208]Adjusting learning rate of group 0 to 8.6982e-03.\n",
      "Adjusting learning rate of group 1 to 4.3491e-04.\n",
      "Epoch 46: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.82, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 47:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]\n",
      "Epoch 47: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.204]Adjusting learning rate of group 0 to 8.6448e-03.\n",
      "Adjusting learning rate of group 1 to 4.3224e-04.\n",
      "Epoch 47: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.76, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 48:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]\n",
      "Epoch 48: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.81, v_num=18, val_loss=3.79, val_acc=0.205]Adjusting learning rate of group 0 to 8.5906e-03.\n",
      "Adjusting learning rate of group 1 to 4.2953e-04.\n",
      "Epoch 48: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.81, v_num=18, val_loss=3.8, val_acc=0.201] \n",
      "Epoch 49:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 49:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]\n",
      "Epoch 49: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.201]Adjusting learning rate of group 0 to 8.5355e-03.\n",
      "Adjusting learning rate of group 1 to 4.2678e-04.\n",
      "Epoch 49: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.8, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 50:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  83%|████████▎ | 500/600 [01:42<00:20,  4.85it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 50: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.95, v_num=18, val_loss=3.8, val_acc=0.204]Adjusting learning rate of group 0 to 8.4796e-03.\n",
      "Adjusting learning rate of group 1 to 4.2398e-04.\n",
      "Epoch 50: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.95, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 51:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]\n",
      "Epoch 51: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.78, v_num=18, val_loss=3.81, val_acc=0.195]Adjusting learning rate of group 0 to 8.4227e-03.\n",
      "Adjusting learning rate of group 1 to 4.2114e-04.\n",
      "Epoch 51: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 52:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  73%|███████▎  | 438/600 [01:38<00:36,  4.42it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]\n",
      "Epoch 52: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.85, v_num=18, val_loss=3.78, val_acc=0.208]Adjusting learning rate of group 0 to 8.3651e-03.\n",
      "Adjusting learning rate of group 1 to 4.1825e-04.\n",
      "Epoch 52: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.85, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 53:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  70%|███████   | 422/600 [01:38<00:41,  4.31it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  71%|███████   | 426/600 [01:38<00:40,  4.33it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  74%|███████▍  | 444/600 [01:39<00:34,  4.46it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  76%|███████▌  | 454/600 [01:40<00:32,  4.53it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  77%|███████▋  | 464/600 [01:40<00:29,  4.60it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  78%|███████▊  | 468/600 [01:41<00:28,  4.63it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  79%|███████▉  | 474/600 [01:41<00:26,  4.67it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  80%|████████  | 480/600 [01:41<00:25,  4.71it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  82%|████████▏ | 490/600 [01:42<00:23,  4.78it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  85%|████████▌ | 510/600 [01:43<00:18,  4.91it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  86%|████████▌ | 514/600 [01:44<00:17,  4.94it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  86%|████████▌ | 516/600 [01:44<00:16,  4.95it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  88%|████████▊ | 530/600 [01:45<00:13,  5.04it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  90%|████████▉ | 538/600 [01:45<00:12,  5.09it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  91%|█████████ | 546/600 [01:46<00:10,  5.14it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  92%|█████████▏| 554/600 [01:46<00:08,  5.19it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  94%|█████████▎| 562/600 [01:47<00:07,  5.24it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  97%|█████████▋| 580/600 [01:48<00:03,  5.35it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  99%|█████████▊| 592/600 [01:49<00:01,  5.42it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]\n",
      "Epoch 53: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.69, v_num=18, val_loss=3.76, val_acc=0.214]Adjusting learning rate of group 0 to 8.3066e-03.\n",
      "Adjusting learning rate of group 1 to 4.1533e-04.\n",
      "Epoch 53: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.69, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 54:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  68%|██████▊   | 408/600 [01:36<00:45,  4.21it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  69%|██████▉   | 416/600 [01:37<00:43,  4.27it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  70%|███████   | 420/600 [01:37<00:41,  4.30it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  71%|███████   | 424/600 [01:38<00:40,  4.33it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  74%|███████▎  | 442/600 [01:39<00:35,  4.46it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  76%|███████▌  | 454/600 [01:39<00:32,  4.54it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  76%|███████▌  | 456/600 [01:40<00:31,  4.56it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  79%|███████▊  | 472/600 [01:41<00:27,  4.67it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  81%|████████▏ | 488/600 [01:42<00:23,  4.78it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  82%|████████▏ | 494/600 [01:42<00:22,  4.82it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  83%|████████▎ | 500/600 [01:42<00:20,  4.86it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  84%|████████▍ | 506/600 [01:43<00:19,  4.90it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  87%|████████▋ | 520/600 [01:44<00:16,  4.99it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  88%|████████▊ | 526/600 [01:44<00:14,  5.03it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  89%|████████▉ | 534/600 [01:45<00:13,  5.08it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  91%|█████████ | 546/600 [01:45<00:10,  5.15it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  94%|█████████▍| 566/600 [01:47<00:06,  5.28it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  97%|█████████▋| 584/600 [01:48<00:02,  5.39it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  99%|█████████▊| 592/600 [01:48<00:01,  5.43it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54:  99%|█████████▉| 596/600 [01:49<00:00,  5.46it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]\n",
      "Epoch 54: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.79, v_num=18, val_loss=3.77, val_acc=0.208]Adjusting learning rate of group 0 to 8.2472e-03.\n",
      "Adjusting learning rate of group 1 to 4.1236e-04.\n",
      "Epoch 54: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.79, v_num=18, val_loss=3.81, val_acc=0.2]  \n",
      "Epoch 55:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 55:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]\n",
      "Epoch 55: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.77, v_num=18, val_loss=3.81, val_acc=0.2]Adjusting learning rate of group 0 to 8.1871e-03.\n",
      "Adjusting learning rate of group 1 to 4.0936e-04.\n",
      "Epoch 55: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.77, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 56:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  67%|██████▋   | 404/600 [01:36<00:46,  4.18it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  68%|██████▊   | 408/600 [01:37<00:45,  4.21it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  69%|██████▊   | 412/600 [01:37<00:44,  4.24it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  75%|███████▌  | 452/600 [01:39<00:32,  4.53it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  77%|███████▋  | 462/600 [01:40<00:30,  4.60it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  90%|█████████ | 542/600 [01:45<00:11,  5.13it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  92%|█████████▏| 550/600 [01:46<00:09,  5.18it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  93%|█████████▎| 558/600 [01:46<00:08,  5.23it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  96%|█████████▌| 576/600 [01:47<00:04,  5.34it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  98%|█████████▊| 586/600 [01:48<00:02,  5.40it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]\n",
      "Epoch 56: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.204]Adjusting learning rate of group 0 to 8.1262e-03.\n",
      "Adjusting learning rate of group 1 to 4.0631e-04.\n",
      "Epoch 56: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.88, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205] \n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 57:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  72%|███████▏  | 430/600 [01:38<00:38,  4.36it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  93%|█████████▎| 560/600 [01:47<00:07,  5.23it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  95%|█████████▌| 570/600 [01:47<00:05,  5.29it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  98%|█████████▊| 590/600 [01:48<00:01,  5.41it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]\n",
      "Epoch 57: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.7, v_num=18, val_loss=3.8, val_acc=0.205]Adjusting learning rate of group 0 to 8.0645e-03.\n",
      "Adjusting learning rate of group 1 to 4.0323e-04.\n",
      "Epoch 57: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.7, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  67%|██████▋   | 400/600 [01:36<00:48,  4.16it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 58:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  72%|███████▏  | 434/600 [01:38<00:37,  4.40it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  73%|███████▎  | 438/600 [01:38<00:36,  4.43it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  75%|███████▍  | 448/600 [01:39<00:33,  4.50it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  76%|███████▋  | 458/600 [01:40<00:31,  4.57it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  78%|███████▊  | 466/600 [01:40<00:28,  4.62it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  78%|███████▊  | 468/600 [01:40<00:28,  4.64it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  80%|███████▉  | 478/600 [01:41<00:25,  4.71it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  81%|████████  | 484/600 [01:41<00:24,  4.75it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  82%|████████▏ | 490/600 [01:42<00:22,  4.79it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  83%|████████▎ | 496/600 [01:42<00:21,  4.83it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  84%|████████▎ | 502/600 [01:43<00:20,  4.87it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  85%|████████▍ | 508/600 [01:43<00:18,  4.91it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  86%|████████▌ | 514/600 [01:43<00:17,  4.95it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  88%|████████▊ | 528/600 [01:44<00:14,  5.04it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  88%|████████▊ | 530/600 [01:44<00:13,  5.05it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  89%|████████▉ | 536/600 [01:45<00:12,  5.09it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  93%|█████████▎| 560/600 [01:46<00:07,  5.24it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  95%|█████████▍| 568/600 [01:47<00:06,  5.29it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  96%|█████████▌| 576/600 [01:47<00:04,  5.33it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  96%|█████████▋| 578/600 [01:48<00:04,  5.35it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  98%|█████████▊| 588/600 [01:48<00:02,  5.41it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58: 100%|█████████▉| 598/600 [01:49<00:00,  5.47it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]\n",
      "Epoch 58: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.78, v_num=18, val_loss=3.78, val_acc=0.21]Adjusting learning rate of group 0 to 8.0021e-03.\n",
      "Adjusting learning rate of group 1 to 4.0011e-04.\n",
      "Epoch 58: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.78, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 59:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  87%|████████▋ | 522/600 [01:44<00:15,  4.99it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  91%|█████████ | 544/600 [01:45<00:10,  5.13it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  92%|█████████▏| 552/600 [01:46<00:09,  5.18it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]\n",
      "Epoch 59: 100%|██████████| 600/600 [01:49<00:00,  5.47it/s, loss=3.64, v_num=18, val_loss=3.77, val_acc=0.211]Adjusting learning rate of group 0 to 7.9389e-03.\n",
      "Adjusting learning rate of group 1 to 3.9695e-04.\n",
      "Epoch 59: 100%|██████████| 600/600 [01:50<00:00,  5.45it/s, loss=3.64, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  67%|██████▋   | 400/600 [01:36<00:48,  4.15it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Validating:   0%|          | 0/200 [00:00<?, ?it/s]\u001b[A\n",
      "Epoch 60:  67%|██████▋   | 402/600 [01:36<00:47,  4.16it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  67%|██████▋   | 404/600 [01:36<00:46,  4.17it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  68%|██████▊   | 406/600 [01:36<00:46,  4.19it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  68%|██████▊   | 408/600 [01:37<00:45,  4.20it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  68%|██████▊   | 410/600 [01:37<00:45,  4.22it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  69%|██████▊   | 412/600 [01:37<00:44,  4.23it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  69%|██████▉   | 414/600 [01:37<00:43,  4.25it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  69%|██████▉   | 416/600 [01:37<00:43,  4.26it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  70%|██████▉   | 418/600 [01:37<00:42,  4.28it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  70%|███████   | 420/600 [01:37<00:41,  4.29it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  70%|███████   | 422/600 [01:37<00:41,  4.31it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  71%|███████   | 424/600 [01:38<00:40,  4.32it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  71%|███████   | 426/600 [01:38<00:40,  4.34it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  71%|███████▏  | 428/600 [01:38<00:39,  4.35it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  72%|███████▏  | 430/600 [01:38<00:38,  4.37it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  72%|███████▏  | 432/600 [01:38<00:38,  4.38it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  72%|███████▏  | 434/600 [01:38<00:37,  4.39it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  73%|███████▎  | 436/600 [01:38<00:37,  4.41it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  73%|███████▎  | 438/600 [01:39<00:36,  4.42it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  73%|███████▎  | 440/600 [01:39<00:36,  4.44it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  74%|███████▎  | 442/600 [01:39<00:35,  4.45it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  74%|███████▍  | 444/600 [01:39<00:34,  4.47it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  74%|███████▍  | 446/600 [01:39<00:34,  4.48it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  75%|███████▍  | 448/600 [01:39<00:33,  4.49it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  75%|███████▌  | 450/600 [01:39<00:33,  4.51it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  75%|███████▌  | 452/600 [01:39<00:32,  4.52it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  76%|███████▌  | 454/600 [01:40<00:32,  4.54it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  76%|███████▌  | 456/600 [01:40<00:31,  4.55it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  76%|███████▋  | 458/600 [01:40<00:31,  4.56it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  77%|███████▋  | 460/600 [01:40<00:30,  4.58it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  77%|███████▋  | 462/600 [01:40<00:30,  4.59it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  77%|███████▋  | 464/600 [01:40<00:29,  4.61it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  78%|███████▊  | 466/600 [01:40<00:29,  4.62it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  78%|███████▊  | 468/600 [01:40<00:28,  4.63it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  78%|███████▊  | 470/600 [01:41<00:27,  4.65it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  79%|███████▊  | 472/600 [01:41<00:27,  4.66it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  79%|███████▉  | 474/600 [01:41<00:26,  4.68it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  79%|███████▉  | 476/600 [01:41<00:26,  4.69it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  80%|███████▉  | 478/600 [01:41<00:25,  4.70it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  80%|████████  | 480/600 [01:41<00:25,  4.72it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  80%|████████  | 482/600 [01:41<00:24,  4.73it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  81%|████████  | 484/600 [01:42<00:24,  4.74it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  81%|████████  | 486/600 [01:42<00:23,  4.76it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  81%|████████▏ | 488/600 [01:42<00:23,  4.77it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  82%|████████▏ | 490/600 [01:42<00:22,  4.78it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  82%|████████▏ | 492/600 [01:42<00:22,  4.80it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  82%|████████▏ | 494/600 [01:42<00:22,  4.81it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  83%|████████▎ | 496/600 [01:42<00:21,  4.82it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  83%|████████▎ | 498/600 [01:42<00:21,  4.84it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  83%|████████▎ | 500/600 [01:43<00:20,  4.85it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  84%|████████▎ | 502/600 [01:43<00:20,  4.86it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  84%|████████▍ | 504/600 [01:43<00:19,  4.88it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  84%|████████▍ | 506/600 [01:43<00:19,  4.89it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  85%|████████▍ | 508/600 [01:43<00:18,  4.90it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  85%|████████▌ | 510/600 [01:43<00:18,  4.92it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  85%|████████▌ | 512/600 [01:43<00:17,  4.93it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  86%|████████▌ | 514/600 [01:43<00:17,  4.94it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  86%|████████▌ | 516/600 [01:44<00:16,  4.96it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  86%|████████▋ | 518/600 [01:44<00:16,  4.97it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  87%|████████▋ | 520/600 [01:44<00:16,  4.98it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  87%|████████▋ | 522/600 [01:44<00:15,  5.00it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  87%|████████▋ | 524/600 [01:44<00:15,  5.01it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  88%|████████▊ | 526/600 [01:44<00:14,  5.02it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  88%|████████▊ | 528/600 [01:44<00:14,  5.03it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  88%|████████▊ | 530/600 [01:45<00:13,  5.05it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  89%|████████▊ | 532/600 [01:45<00:13,  5.06it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  89%|████████▉ | 534/600 [01:45<00:13,  5.07it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  89%|████████▉ | 536/600 [01:45<00:12,  5.08it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  90%|████████▉ | 538/600 [01:45<00:12,  5.10it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  90%|█████████ | 540/600 [01:45<00:11,  5.11it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  90%|█████████ | 542/600 [01:45<00:11,  5.12it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  91%|█████████ | 544/600 [01:45<00:10,  5.14it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  91%|█████████ | 546/600 [01:46<00:10,  5.15it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  91%|█████████▏| 548/600 [01:46<00:10,  5.16it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  92%|█████████▏| 550/600 [01:46<00:09,  5.17it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  92%|█████████▏| 552/600 [01:46<00:09,  5.19it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  92%|█████████▏| 554/600 [01:46<00:08,  5.20it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  93%|█████████▎| 556/600 [01:46<00:08,  5.21it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  93%|█████████▎| 558/600 [01:46<00:08,  5.22it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  93%|█████████▎| 560/600 [01:46<00:07,  5.23it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  94%|█████████▎| 562/600 [01:47<00:07,  5.25it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  94%|█████████▍| 564/600 [01:47<00:06,  5.26it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  94%|█████████▍| 566/600 [01:47<00:06,  5.27it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  95%|█████████▍| 568/600 [01:47<00:06,  5.28it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  95%|█████████▌| 570/600 [01:47<00:05,  5.30it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  95%|█████████▌| 572/600 [01:47<00:05,  5.31it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  96%|█████████▌| 574/600 [01:47<00:04,  5.32it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  96%|█████████▌| 576/600 [01:48<00:04,  5.33it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  96%|█████████▋| 578/600 [01:48<00:04,  5.34it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  97%|█████████▋| 580/600 [01:48<00:03,  5.36it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  97%|█████████▋| 582/600 [01:48<00:03,  5.37it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  97%|█████████▋| 584/600 [01:48<00:02,  5.38it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  98%|█████████▊| 586/600 [01:48<00:02,  5.39it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  98%|█████████▊| 588/600 [01:48<00:02,  5.40it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  98%|█████████▊| 590/600 [01:48<00:01,  5.42it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  99%|█████████▊| 592/600 [01:49<00:01,  5.43it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  99%|█████████▉| 594/600 [01:49<00:01,  5.44it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60:  99%|█████████▉| 596/600 [01:49<00:00,  5.45it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60: 100%|█████████▉| 598/600 [01:49<00:00,  5.46it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]\n",
      "Epoch 60: 100%|██████████| 600/600 [01:49<00:00,  5.48it/s, loss=3.72, v_num=18, val_loss=3.76, val_acc=0.208]Adjusting learning rate of group 0 to 7.8750e-03.\n",
      "Adjusting learning rate of group 1 to 3.9375e-04.\n",
      "Epoch 60: 100%|██████████| 600/600 [01:49<00:00,  5.46it/s, loss=3.72, v_num=18, val_loss=3.79, val_acc=0.209]\n",
      "Epoch 61:  12%|█▏        | 74/600 [00:18<02:08,  4.09it/s, loss=3.64, v_num=18, val_loss=3.79, val_acc=0.209] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving latest checkpoint...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61:  12%|█▏        | 74/600 [00:18<02:12,  3.98it/s, loss=3.64, v_num=18, val_loss=3.79, val_acc=0.209]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Profiler Report\n",
      "\n",
      "Action                      \t|  Mean duration (s)\t|Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "Total                       \t|  -              \t|_              \t|  6766.6         \t|  100 %          \t|\n",
      "-----------------------------------------------------------------------------------------------------------------------------\n",
      "run_training_epoch          \t|  108.65         \t|62             \t|  6736.2         \t|  99.551         \t|\n",
      "run_training_batch          \t|  0.23794        \t|24475          \t|  5823.5         \t|  86.062         \t|\n",
      "evaluation_step_and_end     \t|  0.064434       \t|12202          \t|  786.23         \t|  11.619         \t|\n",
      "optimizer_step_and_closure_0\t|  0.012384       \t|24475          \t|  303.09         \t|  4.4792         \t|\n",
      "training_step_and_backward  \t|  0.011432       \t|24475          \t|  279.79         \t|  4.1348         \t|\n",
      "model_forward               \t|  0.0062307      \t|24475          \t|  152.5          \t|  2.2536         \t|\n",
      "model_backward              \t|  0.0050072      \t|24475          \t|  122.55         \t|  1.8111         \t|\n",
      "get_train_batch             \t|  0.0011539      \t|24475          \t|  28.241         \t|  0.41735        \t|\n",
      "on_train_batch_end          \t|  0.00098989     \t|24474          \t|  24.227         \t|  0.35803        \t|\n",
      "on_validation_end           \t|  0.34942        \t|62             \t|  21.664         \t|  0.32016        \t|\n",
      "on_validation_batch_end     \t|  0.00068504     \t|12202          \t|  8.3589         \t|  0.12353        \t|\n",
      "cache_result                \t|  1.4925e-05     \t|159537         \t|  2.3811         \t|  0.035188       \t|\n",
      "on_batch_start              \t|  1.5958e-05     \t|24475          \t|  0.39058        \t|  0.0057721      \t|\n",
      "on_batch_end                \t|  1.4569e-05     \t|24474          \t|  0.35656        \t|  0.0052693      \t|\n",
      "on_before_zero_grad         \t|  1.0439e-05     \t|24475          \t|  0.25551        \t|  0.003776       \t|\n",
      "on_after_backward           \t|  9.4507e-06     \t|24475          \t|  0.2313         \t|  0.0034183      \t|\n",
      "on_train_batch_start        \t|  7.943e-06      \t|24475          \t|  0.1944         \t|  0.002873       \t|\n",
      "training_step_end           \t|  7.6887e-06     \t|24475          \t|  0.18818        \t|  0.002781       \t|\n",
      "on_validation_batch_start   \t|  9.286e-06      \t|12202          \t|  0.11331        \t|  0.0016745      \t|\n",
      "on_validation_start         \t|  0.0016163      \t|62             \t|  0.10021        \t|  0.0014809      \t|\n",
      "validation_step_end         \t|  7.515e-06      \t|12202          \t|  0.091698       \t|  0.0013551      \t|\n",
      "on_epoch_start              \t|  0.00081972     \t|62             \t|  0.050823       \t|  0.00075108     \t|\n",
      "on_epoch_end                \t|  1.6506e-05     \t|61             \t|  0.0010068      \t|  1.488e-05      \t|\n",
      "on_validation_epoch_end     \t|  1.2596e-05     \t|62             \t|  0.00078096     \t|  1.1541e-05     \t|\n",
      "on_train_end                \t|  0.00065945     \t|1              \t|  0.00065945     \t|  9.7456e-06     \t|\n",
      "on_train_epoch_end          \t|  8.7309e-06     \t|61             \t|  0.00053258     \t|  7.8707e-06     \t|\n",
      "on_train_epoch_start        \t|  8.5547e-06     \t|62             \t|  0.00053039     \t|  7.8383e-06     \t|\n",
      "on_validation_epoch_start   \t|  8.2739e-06     \t|62             \t|  0.00051298     \t|  7.581e-06      \t|\n",
      "on_train_start              \t|  0.00050727     \t|1              \t|  0.00050727     \t|  7.4967e-06     \t|\n",
      "on_fit_start                \t|  1.5501e-05     \t|1              \t|  1.5501e-05     \t|  2.2908e-07     \t|\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_trainer.fit(classifier, train_dataloader=data.train_dataloader(), val_dataloaders=data.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dac74008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cdd58f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    }
   ],
   "source": [
    "# from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_last=True)\n",
    "\n",
    "# EPOCHS = 60\n",
    "# trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/nr2229/BYOL/FineTuned/classifier_byol_resnet34_lightly_new', profiler=\"simple\",\n",
    "#                      limit_val_batches= 0.75, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "78820d06",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = NYUImageNetDataModule()\n",
    "# trainer.fit(classifier, train_dataloader=data.train_dataloader(), val_dataloaders=data.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "41dfecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/scratch/nr2229/BYOL/FineTuned\"\n",
    "\n",
    "torch.save(classifier.state_dict(), os.path.join(checkpoint_dir, 'lightly_resnet34v2_classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "b366713e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = ResNetClassifier()\n",
    "net.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'lightly_resnet34v2_classifier.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92872e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 21.00%\n"
     ]
    }
   ],
   "source": [
    "# net = net.cuda()\n",
    "net = classifier.cuda()\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in data.val_dataloader():\n",
    "#         print(batch)\n",
    "#         break\n",
    "#         images, labels = batch\n",
    "        images = batch[0]\n",
    "        labels = batch[1]\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0974c40d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
