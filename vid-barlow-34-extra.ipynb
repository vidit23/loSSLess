{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e86fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import argparse\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import signal\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "from torch import nn, optim\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "import resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01534fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointDir = 'barlow-custom34-1000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b98070",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, limit=0):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        \n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "        if limit == 0:\n",
    "            self.num_images = len(os.listdir(self.image_dir))\n",
    "        else:\n",
    "            self.num_images = limit\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "            \n",
    "            \n",
    "        if self.split == \"unlabeled\":\n",
    "            label_path = os.path.join(\"label_15.pt\")\n",
    "            if os.path.exists(label_path):\n",
    "                labels = torch.load(label_path)\n",
    "\n",
    "            images = []\n",
    "            f = open(\"requests.txt\", \"r\")\n",
    "            s = str(f.read()).split(\"\\n\")\n",
    "            for img in s:\n",
    "                images.append(int(img.replace(\".png,\",\"\")))\n",
    "                \n",
    "            self.imageLabelDict = { images[i]: labels[i]  for i in range(len(images))} \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "\n",
    "        if self.split == \"unlabeled\" and idx in self.imageLabelDict:\n",
    "            return self.transform(img), self.imageLabelDict[idx]            \n",
    "        else:\n",
    "            return self.transform(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc0293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianBlur(object):\n",
    "    def __init__(self, p):\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, img):\n",
    "        if random.random() < self.p:\n",
    "            sigma = random.random() * 1.9 + 0.1\n",
    "            return img.filter(ImageFilter.GaussianBlur(sigma))\n",
    "        else:\n",
    "            return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUImageNetDataModule(pl.LightningDataModule):\n",
    "    def __init__(self):\n",
    "        self.train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(96, interpolation=Image.BICUBIC),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomApply(\n",
    "                [transforms.ColorJitter(brightness=0.4, contrast=0.4,\n",
    "                                        saturation=0.2, hue=0.1)],\n",
    "                p=0.8\n",
    "            ),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            GaussianBlur(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "    \n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        trainset = CustomDataset(root='/dataset', split=\"train\", transform=self.train_transform)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def extra_train_loader(self):\n",
    "        unlabeledset = CustomDataset(root='/dataset', split=\"unlabeled\", transform=self.train_transform)\n",
    "        unlabeledGivenData = torch.utils.data.Subset(unlabeledset, list(unlabeledset.imageLabelDict.keys()))\n",
    "        trainset = CustomDataset(root='/dataset', split=\"train\", transform=self.train_transform)\n",
    "        trainExtraDataset = torch.utils.data.ConcatDataset((unlabeledGivenData, trainset))\n",
    "        train_loader = torch.utils.data.DataLoader(trainExtraDataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return train_loader\n",
    "        \n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        eval_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        evalset = CustomDataset(root='/dataset', split=\"val\", transform=eval_transform)\n",
    "        eval_loader = torch.utils.data.DataLoader(evalset, batch_size=128, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return eval_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7878fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyudata = NYUImageNetDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851eccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BarlowTwins(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = resnet.get_custom_resnet34()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "\n",
    "        # projector\n",
    "        sizes = [512] + list(map(int, '1024-1024-1024'.split('-')))\n",
    "        layers = []\n",
    "        for i in range(len(sizes) - 2):\n",
    "            layers.append(nn.Linear(sizes[i], sizes[i + 1], bias=False))\n",
    "            layers.append(nn.BatchNorm1d(sizes[i + 1]))\n",
    "            layers.append(nn.ReLU(inplace=True))\n",
    "        layers.append(nn.Linear(sizes[-2], sizes[-1], bias=False))\n",
    "        self.projector = nn.Sequential(*layers)\n",
    "\n",
    "        # normalization layer for the representations z1 and z2\n",
    "        self.bn = nn.BatchNorm1d(sizes[-1], affine=False)\n",
    "        \n",
    "def exclude_bias_and_norm(p):\n",
    "    return p.ndim == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a295c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "model = BarlowTwins().cuda()\n",
    "if os.path.isfile('/scratch/vvb238/' + checkpointDir + '/best-checkpoint.pth'):\n",
    "    ckpt = torch.load('/scratch/vvb238/' + checkpointDir + '/best-checkpoint.pth',\n",
    "                      map_location='cpu')\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "print(ckpt['epoch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b7030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.backbone = torchvision.models.resnet34(zero_init_residual=True)\n",
    "        self.backbone = resnet.get_custom_resnet34()\n",
    "        self.backbone.fc = nn.Identity()\n",
    "        self.backbone.load_state_dict(model.backbone.state_dict())\n",
    "        \n",
    "        self.lastLayer = torch.nn.Sequential(\n",
    "            torch.nn.Linear(512, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            nn.Dropout(p=0.3),\n",
    "#             torch.nn.Linear(1024, 1024),\n",
    "#             torch.nn.ReLU(),\n",
    "#             nn.Dropout(p=0.3),\n",
    "            torch.nn.Linear(1024, 800),\n",
    "        )\n",
    "#         self.lastLayer = torch.nn.Linear(512, 800)\n",
    "        for layer in self.lastLayer.modules():\n",
    "           if isinstance(layer, nn.Linear):\n",
    "                layer.weight.data.normal_(mean=0.0, std=0.01)\n",
    "                layer.bias.data.zero_()\n",
    "        \n",
    "        self.param_groups = [dict(params=self.lastLayer.parameters(), lr=0.01)]\n",
    "        self.param_groups.append(dict(params=model.parameters(), lr=0.0008))\n",
    "        \n",
    "        self.criterion=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.lastLayer(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        classProbs = self.forward(data)\n",
    "        loss = self.criterion(classProbs, label)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def _evaluate(self, batch, batch_idx, stage=None):\n",
    "        x, y = batch\n",
    "        out = self.forward(x)\n",
    "        logits = F.log_softmax(out, dim=-1)\n",
    "        loss = F.nll_loss(logits, y)\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        acc = accuracy(preds, y)\n",
    "\n",
    "        if stage:\n",
    "            self.log(f'{stage}_loss', loss, prog_bar=True)\n",
    "            self.log(f'{stage}_acc', acc, prog_bar=True)\n",
    "\n",
    "        return loss, acc\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        self._evaluate(batch, batch_idx, 'val')[0]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(self.param_groups, 0, momentum=0.9, weight_decay=1e-5)\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, EPOCHS, verbose=True)\n",
    "        return {'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b03d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "classifier = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a59400",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(),\n",
    "           '/scratch/vvb238/' + checkpointDir + '/base-classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1779f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', save_last=True)\n",
    "classifier_trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/vvb238/classifier-' + checkpointDir, profiler=\"simple\",\n",
    "                     limit_val_batches= 0.6, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False, )\n",
    "#                             resume_from_checkpoint='/scratch/vvb238/classifier-barlow-custom34-1000/lightning_logs/version_7/checkpoints/last.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be6015",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "classifier_trainer.fit(classifier, train_dataloader=nyudata.extra_train_loader(), val_dataloaders=nyudata.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0098b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = classifier.cuda()\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in nyudata.val_dataloader():\n",
    "        images, labels = batch\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f85ed06",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (100 * correct / total)\n",
    "print('/scratch/vvb238/extra-' + checkpointDir + '/' + str(accuracy).replace('.', '') + '-extra-classifier.pth')\n",
    "torch.save(classifier.state_dict(),\n",
    "           '/scratch/vvb238/' + checkpointDir + '/' + str(accuracy).replace('.', '') + '-extra-classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f12ce46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
