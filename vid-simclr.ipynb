{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5401ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import NT_Xent, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from simclr.modules.sync_batchnorm import convert_model\n",
    "from simclr.modules import LARS\n",
    "\n",
    "import resnet\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c3e16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, limit=0):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "\n",
    "        if limit == 0:\n",
    "            self.num_images = len(os.listdir(self.image_dir))\n",
    "        else:\n",
    "            self.num_images = limit\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "\n",
    "        return self.transform(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a313809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NYUImageNetDataModule(pl.LightningDataModule):\n",
    "  \n",
    "    def train_dataloader(self):\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "\n",
    "        trainset = CustomDataset(root='/dataset', split=\"train\", transform=train_transform)\n",
    "        train_loader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return train_loader\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        eval_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        evalset = CustomDataset(root='/dataset', split=\"val\", transform=eval_transform)\n",
    "        eval_loader = torch.utils.data.DataLoader(evalset, batch_size=64, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return eval_loader\n",
    "    \n",
    "    def ssl_train_dataloader(self, batch_size):\n",
    "        unlabeled_dataset = CustomDataset(root='/dataset', split='unlabeled', transform=TransformsSimCLR(96))\n",
    "        unlabeled_dataloader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        return unlabeled_dataloader\n",
    "        \n",
    "    def ssl_val_dataloader(self, batch_size):\n",
    "        val_dataset = CustomDataset(root='/dataset', split='val', transform=TransformsSimCLR(96))\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=True)\n",
    "        return val_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e894903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLearning(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # initialize ResNet\n",
    "        self.encoder = resnet.get_custom_resnet18()\n",
    "#         get_resnet(\"resnet18\", pretrained=False)\n",
    "        self.n_features = self.encoder.fc.in_features  # get dimensions of fc layer\n",
    "        self.model = SimCLR(self.encoder, 512, self.n_features)\n",
    "        self.criterion = NT_Xent(\n",
    "            BATCH_SIZE, 0.5, world_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        h_i, h_j, z_i, z_j = self.model(x_i, x_j)\n",
    "        return z_i, z_j\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        (x_i, x_j), _ = batch\n",
    "        z_i, z_j = self.forward(x_i, x_j)\n",
    "        loss = self.criterion(z_i, z_j)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        (x_i, x_j), _ = batch\n",
    "        z_i, z_j = self.forward(x_i, x_j)\n",
    "        loss = self.criterion(z_i, z_j)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return { 'val_loss' : loss }\n",
    "\n",
    "    def configure_criterion(self):\n",
    "        criterion = NT_Xent(BATCH_SIZE, 0.5)\n",
    "        return criterion\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        scheduler = None\n",
    "#       \"Adam\":\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4)\n",
    "    \n",
    "#       \"LARS\"\n",
    "        # optimized using LARS with linear learning rate scaling\n",
    "        # (i.e. LearningRate = 0.3 × BatchSize/256) and weight decay of 10−6.\n",
    "        learning_rate = 0.3 * BATCH_SIZE / 256\n",
    "        optimizer = LARS(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.000001,\n",
    "            exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    "        )\n",
    "\n",
    "        # \"decay the learning rate with the cosine decay schedule without restarts\"\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, EPOCHS, eta_min=0, last_epoch=-1\n",
    "        )\n",
    "\n",
    "        if scheduler:\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            return {\"optimizer\": optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a2d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f89aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unlabeled_dataset = CustomDataset(root='/dataset', split='unlabeled', transform=TransformsSimCLR(96))\n",
    "# unlabeled_dataloader = torch.utils.data.DataLoader(unlabeled_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b9cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_dataset = CustomDataset(root='/dataset', split='val', transform=TransformsSimCLR(96))\n",
    "# val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b4e276",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = NYUImageNetDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4b7db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simclr = ContrastiveLearning()\n",
    "simclr = ContrastiveLearning.load_from_checkpoint('/scratch/vvb238/simclr/simclr.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aa19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_loss', save_last=True)\n",
    "\n",
    "trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/vvb238/simclr', profiler=\"simple\",\n",
    "                     limit_val_batches= 5, precision=16, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)\n",
    "trainer.sync_batchnorm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b6677",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(simclr, train_dataloader=data.ssl_train_dataloader(BATCH_SIZE), val_dataloaders=data.ssl_val_dataloader(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9805b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"/scratch/vvb238/simclr/simclr.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704d1d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"/scratch/vvb238/simclr\"\n",
    "torch.save(simclr.model.encoder.state_dict(), os.path.join(checkpoint_dir, 'simclr_encoder.pth'))\n",
    "torch.save(simclr.model.projector.state_dict(), os.path.join(checkpoint_dir, 'simclr_projector.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52adeddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning on labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05721fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "#         self.encoder = resnet.get_custom_resnet18()\n",
    "#         self.encoder.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'simclr_encoder.pth')))\n",
    "        self.encoder = simclr.model.encoder\n",
    "        self.lastLayer = torch.nn.Linear(512, 800)\n",
    "        self.criterion=torch.nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.lastLayer(x)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        data, label = batch\n",
    "        classProbs = self.forward(data)\n",
    "        loss = self.criterion(classProbs, label)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        data, label = batch\n",
    "        classProbs = self.forward(data)\n",
    "        loss = self.criterion(classProbs, label)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return { 'val_loss' : loss, 'prediction' : classProbs, 'target' : label }\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters())\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5)\n",
    "        return ({'optimizer': optimizer, 'lr_scheduler': scheduler, 'monitor': 'val_loss'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f055332c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = ResNetClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adf6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/vvb238/classifier', profiler=\"simple\",\n",
    "                     limit_val_batches= 0.75, precision=16, benchmark=True, callbacks=[checkpoint_callback], fast_dev_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5316e823",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(classifier, train_dataloader=data.train_dataloader(), val_dataloaders=data.val_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dc1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(classifier.state_dict(), os.path.join(checkpoint_dir, 'classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1131a7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ResNetClassifier()\n",
    "net.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'classifier.pth')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48195ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = net.cuda()\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for batch in data.val_dataloader():\n",
    "        images, labels = batch\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Accuracy: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e3653",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
