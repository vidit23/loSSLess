{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "da9f3b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer, LightningModule\n",
    "\n",
    "from PIL import Image\n",
    "from simclr import SimCLR\n",
    "from simclr.modules import NT_Xent, get_resnet\n",
    "from simclr.modules.transformations import TransformsSimCLR\n",
    "from simclr.modules.sync_batchnorm import convert_model\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7887a9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform, limit=0):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "\n",
    "        if limit == 0:\n",
    "            self.num_images = len(os.listdir(self.image_dir))\n",
    "        else:\n",
    "            self.num_images = limit\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "\n",
    "        return self.transform(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc7c7931",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveLearning(LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "#         self.hparams = args\n",
    "\n",
    "        # initialize ResNet\n",
    "        self.encoder = get_resnet(\"resnet18\", pretrained=False)\n",
    "        self.n_features = self.encoder.fc.in_features  # get dimensions of fc layer\n",
    "        self.model = SimCLR(self.encoder, 512, self.n_features)\n",
    "        self.criterion = NT_Xent(\n",
    "            BATCH_SIZE, 0.5, world_size=1\n",
    "        )\n",
    "\n",
    "    def forward(self, x_i, x_j):\n",
    "        h_i, h_j, z_i, z_j = self.model(x_i, x_j)\n",
    "        loss = self.criterion(z_i, z_j)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defined the train loop. It is independent of forward\n",
    "        (x_i, x_j), _ = batch\n",
    "        loss = self.forward(x_i, x_j)\n",
    "        return loss\n",
    "\n",
    "    def configure_criterion(self):\n",
    "        criterion = NT_Xent(BATCH_SIZE, 0.5)\n",
    "        return criterion\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        scheduler = None\n",
    "#       \"Adam\":\n",
    "        optimizer = torch.optim.Adam(self.model.parameters(), lr=3e-4)\n",
    "    \n",
    "#       \"LARS\"\n",
    "        # optimized using LARS with linear learning rate scaling\n",
    "        # (i.e. LearningRate = 0.3 × BatchSize/256) and weight decay of 10−6.\n",
    "        learning_rate = 0.3 * BATCH_SIZE / 256\n",
    "        optimizer = LARS(\n",
    "            self.model.parameters(),\n",
    "            lr=learning_rate,\n",
    "            weight_decay=0.000001,\n",
    "            exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    "        )\n",
    "\n",
    "        # \"decay the learning rate with the cosine decay schedule without restarts\"\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, EPOCHS, eta_min=0, last_epoch=-1\n",
    "        )\n",
    "\n",
    "        if scheduler:\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": scheduler}\n",
    "        else:\n",
    "            return {\"optimizer\": optimizer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6d29fbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69f0c8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(root='/dataset', split='unlabeled', transform=TransformsSimCLR(96))\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ecdc9197",
   "metadata": {},
   "outputs": [],
   "source": [
    "simclr = ContrastiveLearning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "55ca4d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n"
     ]
    }
   ],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# checkpoint_callback = ModelCheckpoint(monitor='val_loss')\n",
    "\n",
    "trainer = Trainer(gpus=1,deterministic=True, max_epochs=EPOCHS, default_root_dir='/scratch/vvb238/vae', profiler=\"simple\", fast_dev_run=False)\n",
    "#                      callbacks=[checkpoint_callback], fast_dev_run=False)\n",
    "trainer.sync_batchnorm=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261761d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | encoder   | ResNet  | 11.2 M\n",
      "1 | model     | SimCLR  | 11.7 M\n",
      "2 | criterion | NT_Xent | 0     \n",
      "--------------------------------------\n",
      "11.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.7 M    Total params\n",
      "46.803    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 5/2000 [00:03<23:21,  1.42it/s, loss=6.22, v_num=0]  "
     ]
    }
   ],
   "source": [
    "trainer.fit(simclr, train_dataloader=train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbe809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e58e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72875ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fb255b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7fce4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from simclr.modules import LARS\n",
    "\n",
    "encoder = torchvision.models.resnet18(pretrained=False)\n",
    "criterion = NT_Xent(BATCH_SIZE, 0.5, 1)\n",
    "model = SimCLR(encoder, 1024, 512)\n",
    "\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "learning_rate = 0.3 * BATCH_SIZE / 256\n",
    "optimizer = LARS(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    "    weight_decay=0.000001,\n",
    "    exclude_from_weight_decay=[\"batch_normalization\", \"bias\"],\n",
    ")\n",
    "\n",
    "# \"decay the learning rate with the cosine decay schedule without restarts\"\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer, 100, eta_min=0, last_epoch=-1\n",
    ")\n",
    "\n",
    "checkpoint_dir = \"/scratch/vvb238/simclr\"\n",
    "\n",
    "p = checkpoint_dir+\"/simclr_encoder_18.pth\"\n",
    "print(p)\n",
    "check = os.path.exists(checkpoint_dir+\"/simclr_encoder_18.pth\")\n",
    "print(check)\n",
    "\n",
    "if os.path.exists(checkpoint_dir+\"/simclr_encoder_18.pth\"):\n",
    "    print('Loading previous model')\n",
    "    model.encoder.load_state_dict(torch.load(checkpoint_dir +'/simclr_encoder_18.pth'))\n",
    "    model.projector.load_state_dict(torch.load(checkpoint_dir +'/simclr_projector_18.pth'))\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "numOfBatches = len(train_dataset)/train_dataloader.batch_size\n",
    "\n",
    "EPOCHS=10\n",
    "for i in range(EPOCHS):\n",
    "    model.train()\n",
    "    print('Current Epoch: {}'.format(i))\n",
    "    \n",
    "    loss_epoch = 0\n",
    "    for step, ((x_i, x_j), _) in tqdm(enumerate(train_dataloader), total=int(numOfBatches)):\n",
    "        optimizer.zero_grad()\n",
    "        x_i = x_i.cuda(non_blocking=True)\n",
    "        x_j = x_j.cuda(non_blocking=True)\n",
    "\n",
    "        # positive pair, with encoding\n",
    "        h_i, h_j, z_i, z_j = model(x_i, x_j)\n",
    "\n",
    "        loss = criterion(z_i, z_j)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        if step%100==0:\n",
    "            print('Step: {}, Train Loss: {}'.format(step, loss.item()))\n",
    "#             os.makedirs(args.checkpoint_dir, exist_ok=True)\n",
    "        loss_epoch += loss.item()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     loss_epoch = train(train_dataloader, model, criterion, optimizer, args)\n",
    "    torch.save(model.encoder.state_dict(), os.path.join(checkpoint_dir, 'simclr_encoder.pth'))\n",
    "    torch.save(model.projector.state_dict(), os.path.join(checkpoint_dir, 'simclr_projector.pth'))\n",
    "    avg_loss = loss_epoch/len(train_dataloader)\n",
    "    \n",
    "    print('Epoch: {}, Train Loss: {}'.format(i+1, avg_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
