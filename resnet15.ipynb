{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "973b98f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "559d8d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_id = 15\n",
    "team_name = \"loSSLess\"\n",
    "email_address = \"vvb238@nyu.edu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aab8f1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, split, transform):\n",
    "        r\"\"\"\n",
    "        Args:\n",
    "            root: Location of the dataset folder, usually it is /dataset\n",
    "            split: The split you want to used, it should be one of train, val or unlabeled.\n",
    "            transform: the transform you want to applied to the images.\n",
    "        \"\"\"\n",
    "\n",
    "        self.split = split\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_dir = os.path.join(root, split)\n",
    "        label_path = os.path.join(root, f\"{split}_label_tensor.pt\")\n",
    "\n",
    "        self.num_images = len(os.listdir(self.image_dir))\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            self.labels = torch.load(label_path)\n",
    "        else:\n",
    "            self.labels = -1 * torch.ones(self.num_images, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_images\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        with open(os.path.join(self.image_dir, f\"{idx}.png\"), 'rb') as f:\n",
    "            img = Image.open(f).convert('RGB')\n",
    "\n",
    "        return self.transform(img), self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3de883a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d12fa0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CustomDataset(root='/dataset', split=\"train\", transform=train_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a5de3abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes: int, out_planes: int, stride: int = 1, groups: int = 1, dilation: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes: int, out_planes: int, stride: int = 1) -> nn.Conv2d:\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31204bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion: int = 1\n",
    "\n",
    "    def __init__(self, inplanes: int, planes: int, stride: int = 1, downsample: Optional[nn.Module] = None, dilation: int = 1) -> None:\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02e9751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self, block: Type[Union[BasicBlock]], layers: List[int], num_classes: int = 800, zero_init_residual: bool = False, replace_stride_with_dilation: Optional[List[bool]] = None,) -> None:\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.inplanes, kernel_size=3, stride=2, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.inplanes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=False)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=False)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=False)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        \n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.GroupNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        # Zero-initialize the last BN in each residual branch,\n",
    "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
    "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                  nn.init.constant_(m.bn2.weight, 0)  # type: ignore[arg-type]\n",
    "\n",
    "    def _make_layer(self, block: Type[Union[BasicBlock]], planes: int, blocks: int,\n",
    "                    stride: int = 1, dilate: bool = False) -> nn.Sequential:\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, previous_dilation))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=self.dilation))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _forward_impl(self, x: Tensor) -> Tensor:\n",
    "        # See note [TorchScript super()]\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "#         print(\"After first CNN module\", x.shape)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "#         print(\"After first ResNet module\", x.shape)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "#         print(\"After second ResNet module\", x.shape)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "#         print(\"After third ResNet module\", x.shape)\n",
    "\n",
    "        x = self.layer4(x)\n",
    "#         print(\"After fourth ResNet module\", x.shape)\n",
    "\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "#         print(\"After Average pooling module\", x.shape)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "#         print(\"After flattening\", x.shape)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        return self._forward_impl(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a3c0d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet(BasicBlock, [2,2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "692d79f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = model.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "16d71a4c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "[1,    10] loss: 0.205\n",
      "[1,    20] loss: 0.274\n",
      "[1,    30] loss: 0.251\n",
      "[1,    40] loss: 0.228\n",
      "[1,    50] loss: 0.236\n",
      "[1,    60] loss: 0.244\n",
      "[1,    70] loss: 0.251\n",
      "[1,    80] loss: 0.229\n",
      "[1,    90] loss: 0.289\n",
      "[1,   100] loss: 0.267\n",
      "[1,   110] loss: 0.301\n",
      "[1,   120] loss: 0.187\n",
      "[1,   130] loss: 0.264\n",
      "[1,   140] loss: 0.242\n",
      "[1,   150] loss: 0.236\n",
      "[1,   160] loss: 0.248\n",
      "[1,   170] loss: 0.224\n",
      "[1,   180] loss: 0.265\n",
      "[1,   190] loss: 0.262\n",
      "[1,   200] loss: 0.263\n",
      "[1,   210] loss: 0.225\n",
      "[1,   220] loss: 0.252\n",
      "[1,   230] loss: 0.259\n",
      "[1,   240] loss: 0.265\n",
      "[1,   250] loss: 0.214\n",
      "[1,   260] loss: 0.197\n",
      "[1,   270] loss: 0.215\n",
      "[1,   280] loss: 0.212\n",
      "[1,   290] loss: 0.248\n",
      "[1,   300] loss: 0.260\n",
      "[1,   310] loss: 0.239\n",
      "[1,   320] loss: 0.242\n",
      "[1,   330] loss: 0.219\n",
      "[1,   340] loss: 0.218\n",
      "[1,   350] loss: 0.285\n",
      "[1,   360] loss: 0.233\n",
      "[1,   370] loss: 0.229\n",
      "[1,   380] loss: 0.244\n",
      "[1,   390] loss: 0.268\n",
      "[1,   400] loss: 0.259\n",
      "[1,   410] loss: 0.269\n",
      "[1,   420] loss: 0.255\n",
      "[1,   430] loss: 0.309\n",
      "[1,   440] loss: 0.218\n",
      "[1,   450] loss: 0.319\n",
      "[1,   460] loss: 0.235\n",
      "[1,   470] loss: 0.214\n",
      "[1,   480] loss: 0.276\n",
      "[1,   490] loss: 0.274\n",
      "[1,   500] loss: 0.212\n",
      "[1,   510] loss: 0.230\n",
      "[1,   520] loss: 0.228\n",
      "[1,   530] loss: 0.272\n",
      "[1,   540] loss: 0.198\n",
      "[1,   550] loss: 0.315\n",
      "[1,   560] loss: 0.248\n",
      "[1,   570] loss: 0.241\n",
      "[1,   580] loss: 0.296\n",
      "[1,   590] loss: 0.232\n",
      "[1,   600] loss: 0.199\n",
      "[1,   610] loss: 0.319\n",
      "[1,   620] loss: 0.260\n",
      "[1,   630] loss: 0.266\n",
      "[1,   640] loss: 0.246\n",
      "[1,   650] loss: 0.252\n",
      "[1,   660] loss: 0.249\n",
      "[1,   670] loss: 0.274\n",
      "[1,   680] loss: 0.254\n",
      "[1,   690] loss: 0.262\n",
      "[1,   700] loss: 0.229\n",
      "[1,   710] loss: 0.215\n",
      "[1,   720] loss: 0.213\n",
      "[1,   730] loss: 0.234\n",
      "[1,   740] loss: 0.319\n",
      "[1,   750] loss: 0.282\n",
      "[1,   760] loss: 0.268\n",
      "[1,   770] loss: 0.274\n",
      "[1,   780] loss: 0.259\n",
      "[1,   790] loss: 0.275\n",
      "[1,   800] loss: 0.286\n",
      "[2,    10] loss: 0.217\n",
      "[2,    20] loss: 0.238\n",
      "[2,    30] loss: 0.236\n",
      "[2,    40] loss: 0.203\n",
      "[2,    50] loss: 0.209\n",
      "[2,    60] loss: 0.209\n",
      "[2,    70] loss: 0.289\n",
      "[2,    80] loss: 0.227\n",
      "[2,    90] loss: 0.199\n",
      "[2,   100] loss: 0.195\n",
      "[2,   110] loss: 0.230\n",
      "[2,   120] loss: 0.167\n",
      "[2,   130] loss: 0.207\n",
      "[2,   140] loss: 0.183\n",
      "[2,   150] loss: 0.187\n",
      "[2,   160] loss: 0.224\n",
      "[2,   170] loss: 0.177\n",
      "[2,   180] loss: 0.156\n",
      "[2,   190] loss: 0.255\n",
      "[2,   200] loss: 0.239\n",
      "[2,   210] loss: 0.251\n",
      "[2,   220] loss: 0.264\n",
      "[2,   230] loss: 0.223\n",
      "[2,   240] loss: 0.248\n",
      "[2,   250] loss: 0.219\n",
      "[2,   260] loss: 0.254\n",
      "[2,   270] loss: 0.209\n",
      "[2,   280] loss: 0.170\n",
      "[2,   290] loss: 0.187\n",
      "[2,   300] loss: 0.226\n",
      "[2,   310] loss: 0.206\n",
      "[2,   320] loss: 0.257\n",
      "[2,   330] loss: 0.212\n",
      "[2,   340] loss: 0.235\n",
      "[2,   350] loss: 0.222\n",
      "[2,   360] loss: 0.220\n",
      "[2,   370] loss: 0.288\n",
      "[2,   380] loss: 0.307\n",
      "[2,   390] loss: 0.267\n",
      "[2,   400] loss: 0.232\n",
      "[2,   410] loss: 0.244\n",
      "[2,   420] loss: 0.208\n",
      "[2,   430] loss: 0.239\n",
      "[2,   440] loss: 0.208\n",
      "[2,   450] loss: 0.225\n",
      "[2,   460] loss: 0.246\n",
      "[2,   470] loss: 0.207\n",
      "[2,   480] loss: 0.223\n",
      "[2,   490] loss: 0.176\n",
      "[2,   500] loss: 0.216\n",
      "[2,   510] loss: 0.216\n",
      "[2,   520] loss: 0.208\n",
      "[2,   530] loss: 0.240\n",
      "[2,   540] loss: 0.244\n",
      "[2,   550] loss: 0.221\n",
      "[2,   560] loss: 0.243\n",
      "[2,   570] loss: 0.217\n",
      "[2,   580] loss: 0.240\n",
      "[2,   590] loss: 0.179\n",
      "[2,   600] loss: 0.308\n",
      "[2,   610] loss: 0.220\n",
      "[2,   620] loss: 0.254\n",
      "[2,   630] loss: 0.272\n",
      "[2,   640] loss: 0.202\n",
      "[2,   650] loss: 0.238\n",
      "[2,   660] loss: 0.237\n",
      "[2,   670] loss: 0.233\n",
      "[2,   680] loss: 0.252\n",
      "[2,   690] loss: 0.292\n",
      "[2,   700] loss: 0.217\n",
      "[2,   710] loss: 0.230\n",
      "[2,   720] loss: 0.228\n",
      "[2,   730] loss: 0.261\n",
      "[2,   740] loss: 0.270\n",
      "[2,   750] loss: 0.233\n",
      "[2,   760] loss: 0.232\n",
      "[2,   770] loss: 0.245\n",
      "[2,   780] loss: 0.248\n",
      "[2,   790] loss: 0.282\n",
      "[2,   800] loss: 0.251\n",
      "[3,    10] loss: 0.208\n",
      "[3,    20] loss: 0.230\n",
      "[3,    30] loss: 0.215\n",
      "[3,    40] loss: 0.207\n",
      "[3,    50] loss: 0.282\n",
      "[3,    60] loss: 0.206\n",
      "[3,    70] loss: 0.225\n",
      "[3,    80] loss: 0.221\n",
      "[3,    90] loss: 0.229\n",
      "[3,   100] loss: 0.195\n",
      "[3,   110] loss: 0.213\n",
      "[3,   120] loss: 0.276\n",
      "[3,   130] loss: 0.219\n",
      "[3,   140] loss: 0.246\n",
      "[3,   150] loss: 0.215\n",
      "[3,   160] loss: 0.170\n",
      "[3,   170] loss: 0.193\n",
      "[3,   180] loss: 0.189\n",
      "[3,   190] loss: 0.136\n",
      "[3,   200] loss: 0.220\n",
      "[3,   210] loss: 0.228\n",
      "[3,   220] loss: 0.163\n",
      "[3,   230] loss: 0.260\n",
      "[3,   240] loss: 0.268\n",
      "[3,   250] loss: 0.228\n",
      "[3,   260] loss: 0.251\n",
      "[3,   270] loss: 0.223\n",
      "[3,   280] loss: 0.189\n",
      "[3,   290] loss: 0.247\n",
      "[3,   300] loss: 0.210\n",
      "[3,   310] loss: 0.205\n",
      "[3,   320] loss: 0.199\n",
      "[3,   330] loss: 0.277\n",
      "[3,   340] loss: 0.257\n",
      "[3,   350] loss: 0.215\n",
      "[3,   360] loss: 0.205\n",
      "[3,   370] loss: 0.181\n",
      "[3,   380] loss: 0.161\n",
      "[3,   390] loss: 0.186\n",
      "[3,   400] loss: 0.258\n",
      "[3,   410] loss: 0.197\n",
      "[3,   420] loss: 0.267\n",
      "[3,   430] loss: 0.227\n",
      "[3,   440] loss: 0.230\n",
      "[3,   450] loss: 0.230\n",
      "[3,   460] loss: 0.174\n",
      "[3,   470] loss: 0.249\n",
      "[3,   480] loss: 0.238\n",
      "[3,   490] loss: 0.208\n",
      "[3,   500] loss: 0.217\n",
      "[3,   510] loss: 0.254\n",
      "[3,   520] loss: 0.220\n",
      "[3,   530] loss: 0.197\n",
      "[3,   540] loss: 0.257\n",
      "[3,   550] loss: 0.178\n",
      "[3,   560] loss: 0.246\n",
      "[3,   570] loss: 0.205\n",
      "[3,   580] loss: 0.239\n",
      "[3,   590] loss: 0.182\n",
      "[3,   600] loss: 0.218\n",
      "[3,   610] loss: 0.264\n",
      "[3,   620] loss: 0.270\n",
      "[3,   630] loss: 0.261\n",
      "[3,   640] loss: 0.270\n",
      "[3,   650] loss: 0.276\n",
      "[3,   660] loss: 0.244\n",
      "[3,   670] loss: 0.197\n",
      "[3,   680] loss: 0.165\n",
      "[3,   690] loss: 0.241\n",
      "[3,   700] loss: 0.198\n",
      "[3,   710] loss: 0.237\n",
      "[3,   720] loss: 0.231\n",
      "[3,   730] loss: 0.215\n",
      "[3,   740] loss: 0.204\n",
      "[3,   750] loss: 0.228\n",
      "[3,   760] loss: 0.263\n",
      "[3,   770] loss: 0.227\n",
      "[3,   780] loss: 0.202\n",
      "[3,   790] loss: 0.240\n",
      "[3,   800] loss: 0.209\n",
      "[4,    10] loss: 0.226\n",
      "[4,    20] loss: 0.210\n",
      "[4,    30] loss: 0.196\n",
      "[4,    40] loss: 0.223\n",
      "[4,    50] loss: 0.206\n",
      "[4,    60] loss: 0.170\n",
      "[4,    70] loss: 0.186\n",
      "[4,    80] loss: 0.172\n",
      "[4,    90] loss: 0.206\n",
      "[4,   100] loss: 0.250\n",
      "[4,   110] loss: 0.205\n",
      "[4,   120] loss: 0.181\n",
      "[4,   130] loss: 0.234\n",
      "[4,   140] loss: 0.209\n",
      "[4,   150] loss: 0.182\n",
      "[4,   160] loss: 0.170\n",
      "[4,   170] loss: 0.213\n",
      "[4,   180] loss: 0.259\n",
      "[4,   190] loss: 0.215\n",
      "[4,   200] loss: 0.212\n",
      "[4,   210] loss: 0.217\n",
      "[4,   220] loss: 0.178\n",
      "[4,   230] loss: 0.170\n",
      "[4,   240] loss: 0.169\n",
      "[4,   250] loss: 0.170\n",
      "[4,   260] loss: 0.196\n",
      "[4,   270] loss: 0.178\n",
      "[4,   280] loss: 0.252\n",
      "[4,   290] loss: 0.180\n",
      "[4,   300] loss: 0.190\n",
      "[4,   310] loss: 0.208\n",
      "[4,   320] loss: 0.237\n",
      "[4,   330] loss: 0.212\n",
      "[4,   340] loss: 0.198\n",
      "[4,   350] loss: 0.235\n",
      "[4,   360] loss: 0.212\n",
      "[4,   370] loss: 0.202\n",
      "[4,   380] loss: 0.170\n",
      "[4,   390] loss: 0.195\n",
      "[4,   400] loss: 0.229\n",
      "[4,   410] loss: 0.208\n",
      "[4,   420] loss: 0.199\n",
      "[4,   430] loss: 0.186\n",
      "[4,   440] loss: 0.200\n",
      "[4,   450] loss: 0.209\n",
      "[4,   460] loss: 0.184\n",
      "[4,   470] loss: 0.181\n",
      "[4,   480] loss: 0.239\n",
      "[4,   490] loss: 0.197\n",
      "[4,   500] loss: 0.210\n",
      "[4,   510] loss: 0.160\n",
      "[4,   520] loss: 0.186\n",
      "[4,   530] loss: 0.193\n",
      "[4,   540] loss: 0.230\n",
      "[4,   550] loss: 0.242\n",
      "[4,   560] loss: 0.234\n",
      "[4,   570] loss: 0.220\n",
      "[4,   580] loss: 0.235\n",
      "[4,   590] loss: 0.199\n",
      "[4,   600] loss: 0.167\n",
      "[4,   610] loss: 0.218\n",
      "[4,   620] loss: 0.188\n",
      "[4,   630] loss: 0.180\n",
      "[4,   640] loss: 0.265\n",
      "[4,   650] loss: 0.193\n",
      "[4,   660] loss: 0.214\n",
      "[4,   670] loss: 0.176\n",
      "[4,   680] loss: 0.239\n",
      "[4,   690] loss: 0.207\n",
      "[4,   700] loss: 0.267\n",
      "[4,   710] loss: 0.270\n",
      "[4,   720] loss: 0.250\n",
      "[4,   730] loss: 0.219\n",
      "[4,   740] loss: 0.260\n",
      "[4,   750] loss: 0.223\n",
      "[4,   760] loss: 0.220\n",
      "[4,   770] loss: 0.219\n",
      "[4,   780] loss: 0.225\n",
      "[4,   790] loss: 0.225\n",
      "[4,   800] loss: 0.250\n",
      "[5,    10] loss: 0.178\n",
      "[5,    20] loss: 0.244\n",
      "[5,    30] loss: 0.178\n",
      "[5,    40] loss: 0.235\n",
      "[5,    50] loss: 0.222\n",
      "[5,    60] loss: 0.175\n",
      "[5,    70] loss: 0.225\n",
      "[5,    80] loss: 0.162\n",
      "[5,    90] loss: 0.208\n",
      "[5,   100] loss: 0.168\n",
      "[5,   110] loss: 0.186\n",
      "[5,   120] loss: 0.161\n",
      "[5,   130] loss: 0.186\n",
      "[5,   140] loss: 0.150\n",
      "[5,   150] loss: 0.172\n",
      "[5,   160] loss: 0.162\n",
      "[5,   170] loss: 0.198\n",
      "[5,   180] loss: 0.171\n",
      "[5,   190] loss: 0.180\n",
      "[5,   200] loss: 0.172\n",
      "[5,   210] loss: 0.182\n",
      "[5,   220] loss: 0.174\n",
      "[5,   230] loss: 0.206\n",
      "[5,   240] loss: 0.167\n",
      "[5,   250] loss: 0.186\n",
      "[5,   260] loss: 0.174\n",
      "[5,   270] loss: 0.157\n",
      "[5,   280] loss: 0.183\n",
      "[5,   290] loss: 0.196\n",
      "[5,   300] loss: 0.204\n",
      "[5,   310] loss: 0.234\n",
      "[5,   320] loss: 0.211\n",
      "[5,   330] loss: 0.199\n",
      "[5,   340] loss: 0.221\n",
      "[5,   350] loss: 0.179\n",
      "[5,   360] loss: 0.186\n",
      "[5,   370] loss: 0.214\n",
      "[5,   380] loss: 0.194\n",
      "[5,   390] loss: 0.273\n",
      "[5,   400] loss: 0.177\n",
      "[5,   410] loss: 0.203\n",
      "[5,   420] loss: 0.196\n",
      "[5,   430] loss: 0.220\n",
      "[5,   440] loss: 0.148\n",
      "[5,   450] loss: 0.183\n",
      "[5,   460] loss: 0.217\n",
      "[5,   470] loss: 0.164\n",
      "[5,   480] loss: 0.184\n",
      "[5,   490] loss: 0.200\n",
      "[5,   500] loss: 0.215\n",
      "[5,   510] loss: 0.183\n",
      "[5,   520] loss: 0.207\n",
      "[5,   530] loss: 0.170\n",
      "[5,   540] loss: 0.217\n",
      "[5,   550] loss: 0.193\n",
      "[5,   560] loss: 0.193\n",
      "[5,   570] loss: 0.267\n",
      "[5,   580] loss: 0.199\n",
      "[5,   590] loss: 0.199\n",
      "[5,   600] loss: 0.184\n",
      "[5,   610] loss: 0.178\n",
      "[5,   620] loss: 0.206\n",
      "[5,   630] loss: 0.198\n",
      "[5,   640] loss: 0.162\n",
      "[5,   650] loss: 0.225\n",
      "[5,   660] loss: 0.183\n",
      "[5,   670] loss: 0.194\n",
      "[5,   680] loss: 0.248\n",
      "[5,   690] loss: 0.205\n",
      "[5,   700] loss: 0.189\n",
      "[5,   710] loss: 0.209\n",
      "[5,   720] loss: 0.219\n",
      "[5,   730] loss: 0.225\n",
      "[5,   740] loss: 0.225\n",
      "[5,   750] loss: 0.215\n",
      "[5,   760] loss: 0.210\n",
      "[5,   770] loss: 0.242\n",
      "[5,   780] loss: 0.197\n",
      "[5,   790] loss: 0.210\n",
      "[5,   800] loss: 0.197\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "print('Start Training')\n",
    "\n",
    "net.train()\n",
    "for epoch in range(100):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "#         break\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:    # print every 10 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "            running_loss = 0.0\n",
    "#     break\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cfe5700",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_location = '/scratch/vvb238/models/'\n",
    "os.makedirs(save_model_location, exist_ok=True)\n",
    "torch.save(net.state_dict(), os.path.join(save_model_location, \"resnet18.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aeaa2e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Team 15: loSSLess Accuracy: 6.36%\n"
     ]
    }
   ],
   "source": [
    "evalset = CustomDataset(root='/dataset', split=\"val\", transform=eval_transform)\n",
    "evalloader = torch.utils.data.DataLoader(evalset, batch_size=256, shuffle=False, num_workers=2)\n",
    "\n",
    "net = model.cuda()\n",
    "\n",
    "net.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in evalloader:\n",
    "        images, labels = data\n",
    "\n",
    "        images = images.cuda()\n",
    "        labels = labels.cuda()\n",
    "\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "\n",
    "print(f\"Team {team_id}: {team_name} Accuracy: {(100 * correct / total):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543b74ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
